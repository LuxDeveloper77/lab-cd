
==> Audit <==
|---------|----------------------|----------|---------|---------|---------------------|---------------------|
| Command |         Args         | Profile  |  User   | Version |     Start Time      |      End Time       |
|---------|----------------------|----------|---------|---------|---------------------|---------------------|
| start   | --driver=docker      | minikube | debiann | v1.35.0 | 24 Mar 25 05:58 EDT | 24 Mar 25 06:02 EDT |
| addons  | enable ingress       | minikube | debiann | v1.35.0 | 24 Mar 25 09:02 EDT | 24 Mar 25 09:03 EDT |
| stop    |                      | minikube | debiann | v1.35.0 | 24 Mar 25 12:40 EDT | 24 Mar 25 12:40 EDT |
| delete  |                      | minikube | debiann | v1.35.0 | 24 Mar 25 12:41 EDT | 24 Mar 25 12:41 EDT |
| delete  | --all                | minikube | debiann | v1.35.0 | 24 Mar 25 12:42 EDT | 24 Mar 25 12:42 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 24 Mar 25 12:43 EDT | 24 Mar 25 12:47 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 24 Mar 25 13:26 EDT | 24 Mar 25 13:27 EDT |
| addons  | enable ingress       | minikube | debiann | v1.35.0 | 24 Mar 25 13:50 EDT | 24 Mar 25 13:51 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 24 Mar 25 19:45 EDT | 24 Mar 25 19:46 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 25 Mar 25 04:25 EDT | 25 Mar 25 04:25 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 25 Mar 25 05:52 EDT | 25 Mar 25 05:52 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 25 Mar 25 10:57 EDT | 25 Mar 25 10:58 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 31 Mar 25 06:09 EDT | 31 Mar 25 06:09 EDT |
| start   |                      | minikube | debiann | v1.35.0 | 02 Apr 25 13:18 EDT | 02 Apr 25 13:18 EDT |
| service | list                 | minikube | debiann | v1.35.0 | 02 Apr 25 13:25 EDT | 02 Apr 25 13:25 EDT |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 13:25 EDT |                     |
| service | list                 | minikube | debiann | v1.35.0 | 02 Apr 25 13:35 EDT | 02 Apr 25 13:35 EDT |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 13:35 EDT |                     |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 13:40 EDT | 02 Apr 25 13:40 EDT |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 14:08 EDT | 02 Apr 25 14:08 EDT |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 14:10 EDT | 02 Apr 25 14:10 EDT |
| ssh     |                      | minikube | debiann | v1.35.0 | 02 Apr 25 14:11 EDT |                     |
| ssh     |                      | minikube | debiann | v1.35.0 | 02 Apr 25 15:52 EDT | 02 Apr 25 15:52 EDT |
| ip      |                      | minikube | debiann | v1.35.0 | 02 Apr 25 16:00 EDT | 02 Apr 25 16:00 EDT |
| ip      |                      | minikube | debiann | v1.35.0 | 02 Apr 25 16:01 EDT | 02 Apr 25 16:01 EDT |
| ip      |                      | minikube | debiann | v1.35.0 | 02 Apr 25 16:03 EDT | 02 Apr 25 16:03 EDT |
| ip      |                      | minikube | debiann | v1.35.0 | 02 Apr 25 16:04 EDT | 02 Apr 25 16:04 EDT |
| ip      |                      | minikube | debiann | v1.35.0 | 02 Apr 25 16:05 EDT | 02 Apr 25 16:05 EDT |
| addons  | enable ingressnginx  | minikube | debiann | v1.35.0 | 02 Apr 25 16:11 EDT |                     |
| addons  | enable ingress-nginx | minikube | debiann | v1.35.0 | 02 Apr 25 16:11 EDT |                     |
| addons  |                      | minikube | debiann | v1.35.0 | 02 Apr 25 16:12 EDT | 02 Apr 25 16:12 EDT |
| addons  | list                 | minikube | debiann | v1.35.0 | 02 Apr 25 16:12 EDT | 02 Apr 25 16:12 EDT |
| addons  | list                 | minikube | debiann | v1.35.0 | 02 Apr 25 16:12 EDT | 02 Apr 25 16:12 EDT |
| ip      |                      | minikube | debiann | v1.35.0 | 02 Apr 25 16:33 EDT | 02 Apr 25 16:33 EDT |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 16:38 EDT | 02 Apr 25 16:38 EDT |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 16:39 EDT | 02 Apr 25 16:39 EDT |
| service | list                 | minikube | debiann | v1.35.0 | 02 Apr 25 16:40 EDT | 02 Apr 25 16:40 EDT |
| service | nodejs-app --url     | minikube | debiann | v1.35.0 | 02 Apr 25 16:47 EDT | 02 Apr 25 16:47 EDT |
|---------|----------------------|----------|---------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2025/04/02 13:18:16
Running on machine: debian
Binary: Built with gc go1.23.4 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0402 13:18:16.547872    2204 out.go:345] Setting OutFile to fd 1 ...
I0402 13:18:16.548023    2204 out.go:397] isatty.IsTerminal(1) = true
I0402 13:18:16.548027    2204 out.go:358] Setting ErrFile to fd 2...
I0402 13:18:16.548031    2204 out.go:397] isatty.IsTerminal(2) = true
I0402 13:18:16.548278    2204 root.go:338] Updating PATH: /home/debiann/.minikube/bin
I0402 13:18:16.552043    2204 out.go:352] Setting JSON to false
I0402 13:18:16.574203    2204 start.go:129] hostinfo: {"hostname":"debian","uptime":2007,"bootTime":1743612289,"procs":156,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"12.10","kernelVersion":"6.1.0-32-amd64","kernelArch":"x86_64","virtualizationSystem":"vbox","virtualizationRole":"guest","hostId":"96d54ac3-1775-4a86-866a-fe2fb82cc0e1"}
I0402 13:18:16.575243    2204 start.go:139] virtualization: vbox guest
I0402 13:18:16.578733    2204 out.go:177] 😄  minikube v1.35.0 on Debian 12.10 (vbox/amd64)
I0402 13:18:16.583037    2204 notify.go:220] Checking for updates...
I0402 13:18:16.584374    2204 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.32.0
I0402 13:18:16.586908    2204 driver.go:394] Setting default libvirt URI to qemu:///system
I0402 13:18:16.641488    2204 docker.go:123] docker version: linux-28.0.2:Docker Engine - Community
I0402 13:18:16.641549    2204 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0402 13:18:17.025560    2204 info.go:266] docker info: {ID:a4a65837-3eb4-4c64-b9cc-e140e0369155 Containers:1 ContainersRunning:0 ContainersPaused:0 ContainersStopped:1 Images:2 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:23 OomKillDisable:false NGoroutines:41 SystemTime:2025-04-02 13:18:17.014230942 -0400 EDT LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.1.0-32-amd64 OperatingSystem:Debian GNU/Linux 12 (bookworm) OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[::1/128 127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4054638592 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:debian Labels:[] ExperimentalBuild:false ServerVersion:28.0.2 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:bcc810d6b9066471b0b6fa75f557a15a1cbf31bb Expected:bcc810d6b9066471b0b6fa75f557a15a1cbf31bb} RuncCommit:{ID:v1.2.4-0-g6c52b3f Expected:v1.2.4-0-g6c52b3f} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.22.0] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.34.0]] Warnings:<nil>}}
I0402 13:18:17.025639    2204 docker.go:318] overlay module found
I0402 13:18:17.028438    2204 out.go:177] ✨  Using the docker driver based on existing profile
I0402 13:18:17.030690    2204 start.go:297] selected driver: docker
I0402 13:18:17.030695    2204 start.go:901] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true ingress:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/debiann:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0402 13:18:17.030750    2204 start.go:912] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0402 13:18:17.030808    2204 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0402 13:18:17.103827    2204 info.go:266] docker info: {ID:a4a65837-3eb4-4c64-b9cc-e140e0369155 Containers:1 ContainersRunning:0 ContainersPaused:0 ContainersStopped:1 Images:2 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:23 OomKillDisable:false NGoroutines:41 SystemTime:2025-04-02 13:18:17.08978189 -0400 EDT LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.1.0-32-amd64 OperatingSystem:Debian GNU/Linux 12 (bookworm) OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[::1/128 127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4054638592 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:debian Labels:[] ExperimentalBuild:false ServerVersion:28.0.2 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:bcc810d6b9066471b0b6fa75f557a15a1cbf31bb Expected:bcc810d6b9066471b0b6fa75f557a15a1cbf31bb} RuncCommit:{ID:v1.2.4-0-g6c52b3f Expected:v1.2.4-0-g6c52b3f} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.22.0] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.34.0]] Warnings:<nil>}}
I0402 13:18:17.104426    2204 cni.go:84] Creating CNI manager for ""
I0402 13:18:17.106410    2204 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0402 13:18:17.106451    2204 start.go:340] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true ingress:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/debiann:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0402 13:18:17.110164    2204 out.go:177] 👍  Starting "minikube" primary control-plane node in "minikube" cluster
I0402 13:18:17.113557    2204 cache.go:121] Beginning downloading kic base image for docker with docker
I0402 13:18:17.115557    2204 out.go:177] 🚜  Pulling base image v0.0.46 ...
I0402 13:18:17.117506    2204 preload.go:131] Checking if preload exists for k8s version v1.32.0 and runtime docker
I0402 13:18:17.117543    2204 preload.go:146] Found local preload: /home/debiann/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.32.0-docker-overlay2-amd64.tar.lz4
I0402 13:18:17.117549    2204 cache.go:56] Caching tarball of preloaded images
I0402 13:18:17.117587    2204 image.go:81] Checking for gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 in local docker daemon
I0402 13:18:17.117766    2204 preload.go:172] Found /home/debiann/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.32.0-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0402 13:18:17.117774    2204 cache.go:59] Finished verifying existence of preloaded tar for v1.32.0 on docker
I0402 13:18:17.117884    2204 profile.go:143] Saving config to /home/debiann/.minikube/profiles/minikube/config.json ...
I0402 13:18:17.146578    2204 image.go:100] Found gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 in local docker daemon, skipping pull
I0402 13:18:17.146587    2204 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 exists in daemon, skipping load
I0402 13:18:17.146636    2204 cache.go:227] Successfully downloaded all kic artifacts
I0402 13:18:17.146655    2204 start.go:360] acquireMachinesLock for minikube: {Name:mkc729e2907cee8da86baa29f5aba87435d02f96 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0402 13:18:17.146796    2204 start.go:364] duration metric: took 121.412µs to acquireMachinesLock for "minikube"
I0402 13:18:17.146812    2204 start.go:96] Skipping create...Using existing machine configuration
I0402 13:18:17.146815    2204 fix.go:54] fixHost starting: 
I0402 13:18:17.147121    2204 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0402 13:18:17.174544    2204 fix.go:112] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0402 13:18:17.174558    2204 fix.go:138] unexpected machine state, will restart: <nil>
I0402 13:18:17.177883    2204 out.go:177] 🔄  Restarting existing docker container for "minikube" ...
I0402 13:18:17.179764    2204 cli_runner.go:164] Run: docker start minikube
I0402 13:18:17.722312    2204 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0402 13:18:17.763193    2204 kic.go:430] container "minikube" state is running.
I0402 13:18:17.763521    2204 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0402 13:18:17.788011    2204 profile.go:143] Saving config to /home/debiann/.minikube/profiles/minikube/config.json ...
I0402 13:18:17.788242    2204 machine.go:93] provisionDockerMachine start ...
I0402 13:18:17.788279    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:17.818658    2204 main.go:141] libmachine: Using SSH client type: native
I0402 13:18:17.820217    2204 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0402 13:18:17.820223    2204 main.go:141] libmachine: About to run SSH command:
hostname
I0402 13:18:17.821739    2204 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:34834->127.0.0.1:32768: read: connection reset by peer
I0402 13:18:20.970599    2204 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0402 13:18:20.970611    2204 ubuntu.go:169] provisioning hostname "minikube"
I0402 13:18:20.970651    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:21.001244    2204 main.go:141] libmachine: Using SSH client type: native
I0402 13:18:21.001371    2204 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0402 13:18:21.001376    2204 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0402 13:18:21.205686    2204 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0402 13:18:21.205729    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:21.254633    2204 main.go:141] libmachine: Using SSH client type: native
I0402 13:18:21.254750    2204 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0402 13:18:21.254758    2204 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0402 13:18:21.386750    2204 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0402 13:18:21.386773    2204 ubuntu.go:175] set auth options {CertDir:/home/debiann/.minikube CaCertPath:/home/debiann/.minikube/certs/ca.pem CaPrivateKeyPath:/home/debiann/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/debiann/.minikube/machines/server.pem ServerKeyPath:/home/debiann/.minikube/machines/server-key.pem ClientKeyPath:/home/debiann/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/debiann/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/debiann/.minikube}
I0402 13:18:21.386784    2204 ubuntu.go:177] setting up certificates
I0402 13:18:21.386790    2204 provision.go:84] configureAuth start
I0402 13:18:21.386823    2204 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0402 13:18:21.419816    2204 provision.go:143] copyHostCerts
I0402 13:18:21.420546    2204 exec_runner.go:144] found /home/debiann/.minikube/ca.pem, removing ...
I0402 13:18:21.421586    2204 exec_runner.go:203] rm: /home/debiann/.minikube/ca.pem
I0402 13:18:21.421631    2204 exec_runner.go:151] cp: /home/debiann/.minikube/certs/ca.pem --> /home/debiann/.minikube/ca.pem (1082 bytes)
I0402 13:18:21.423302    2204 exec_runner.go:144] found /home/debiann/.minikube/cert.pem, removing ...
I0402 13:18:21.423308    2204 exec_runner.go:203] rm: /home/debiann/.minikube/cert.pem
I0402 13:18:21.423335    2204 exec_runner.go:151] cp: /home/debiann/.minikube/certs/cert.pem --> /home/debiann/.minikube/cert.pem (1123 bytes)
I0402 13:18:21.425970    2204 exec_runner.go:144] found /home/debiann/.minikube/key.pem, removing ...
I0402 13:18:21.425975    2204 exec_runner.go:203] rm: /home/debiann/.minikube/key.pem
I0402 13:18:21.426002    2204 exec_runner.go:151] cp: /home/debiann/.minikube/certs/key.pem --> /home/debiann/.minikube/key.pem (1679 bytes)
I0402 13:18:21.426476    2204 provision.go:117] generating server cert: /home/debiann/.minikube/machines/server.pem ca-key=/home/debiann/.minikube/certs/ca.pem private-key=/home/debiann/.minikube/certs/ca-key.pem org=debiann.minikube san=[127.0.0.1 192.168.49.2 localhost minikube]
I0402 13:18:21.470584    2204 provision.go:177] copyRemoteCerts
I0402 13:18:21.471826    2204 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0402 13:18:21.471867    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:21.497405    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:21.592406    2204 ssh_runner.go:362] scp /home/debiann/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0402 13:18:21.625946    2204 ssh_runner.go:362] scp /home/debiann/.minikube/machines/server.pem --> /etc/docker/server.pem (1180 bytes)
I0402 13:18:21.657340    2204 ssh_runner.go:362] scp /home/debiann/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0402 13:18:21.696518    2204 provision.go:87] duration metric: took 309.718433ms to configureAuth
I0402 13:18:21.696531    2204 ubuntu.go:193] setting minikube options for container-runtime
I0402 13:18:21.696640    2204 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.32.0
I0402 13:18:21.696670    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:21.731288    2204 main.go:141] libmachine: Using SSH client type: native
I0402 13:18:21.731412    2204 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0402 13:18:21.731416    2204 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0402 13:18:21.865666    2204 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0402 13:18:21.865676    2204 ubuntu.go:71] root file system type: overlay
I0402 13:18:21.865733    2204 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I0402 13:18:21.865770    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:21.886936    2204 main.go:141] libmachine: Using SSH client type: native
I0402 13:18:21.887057    2204 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0402 13:18:21.887092    2204 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0402 13:18:22.049894    2204 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0402 13:18:22.049948    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:22.071384    2204 main.go:141] libmachine: Using SSH client type: native
I0402 13:18:22.071511    2204 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x8641c0] 0x866ea0 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0402 13:18:22.071520    2204 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0402 13:18:22.215158    2204 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0402 13:18:22.215171    2204 machine.go:96] duration metric: took 4.426922981s to provisionDockerMachine
I0402 13:18:22.215177    2204 start.go:293] postStartSetup for "minikube" (driver="docker")
I0402 13:18:22.215187    2204 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0402 13:18:22.215221    2204 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0402 13:18:22.215244    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:22.236284    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:22.340642    2204 ssh_runner.go:195] Run: cat /etc/os-release
I0402 13:18:22.347426    2204 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0402 13:18:22.347439    2204 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0402 13:18:22.347443    2204 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0402 13:18:22.347447    2204 info.go:137] Remote host: Ubuntu 22.04.5 LTS
I0402 13:18:22.347453    2204 filesync.go:126] Scanning /home/debiann/.minikube/addons for local assets ...
I0402 13:18:22.348145    2204 filesync.go:126] Scanning /home/debiann/.minikube/files for local assets ...
I0402 13:18:22.348834    2204 start.go:296] duration metric: took 133.651205ms for postStartSetup
I0402 13:18:22.348873    2204 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0402 13:18:22.348895    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:22.369033    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:22.467784    2204 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0402 13:18:22.474047    2204 fix.go:56] duration metric: took 5.327227828s for fixHost
I0402 13:18:22.474056    2204 start.go:83] releasing machines lock for "minikube", held for 5.327253146s
I0402 13:18:22.474099    2204 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0402 13:18:22.495645    2204 ssh_runner.go:195] Run: cat /version.json
I0402 13:18:22.495673    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:22.495955    2204 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0402 13:18:22.495985    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:22.515326    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:22.526637    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:24.179081    2204 ssh_runner.go:235] Completed: cat /version.json: (1.683421203s)
I0402 13:18:24.179119    2204 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (1.683152473s)
I0402 13:18:24.179168    2204 ssh_runner.go:195] Run: systemctl --version
I0402 13:18:24.189212    2204 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0402 13:18:24.196109    2204 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0402 13:18:24.222370    2204 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0402 13:18:24.222412    2204 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%p, " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0402 13:18:24.233744    2204 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0402 13:18:24.233755    2204 start.go:495] detecting cgroup driver to use...
I0402 13:18:24.233778    2204 detect.go:190] detected "systemd" cgroup driver on host os
I0402 13:18:24.233957    2204 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0402 13:18:24.255664    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.10"|' /etc/containerd/config.toml"
I0402 13:18:24.270026    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0402 13:18:24.282791    2204 containerd.go:146] configuring containerd to use "systemd" as cgroup driver...
I0402 13:18:24.282818    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = true|g' /etc/containerd/config.toml"
I0402 13:18:24.296672    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0402 13:18:24.310369    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0402 13:18:24.323270    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0402 13:18:24.336411    2204 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0402 13:18:24.347841    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0402 13:18:24.361169    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I0402 13:18:24.374502    2204 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I0402 13:18:24.386961    2204 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0402 13:18:24.399704    2204 crio.go:166] couldn't verify netfilter by "sudo sysctl net.bridge.bridge-nf-call-iptables" which might be okay. error: sudo sysctl net.bridge.bridge-nf-call-iptables: Process exited with status 255
stdout:

stderr:
sysctl: cannot stat /proc/sys/net/bridge/bridge-nf-call-iptables: No such file or directory
I0402 13:18:24.399727    2204 ssh_runner.go:195] Run: sudo modprobe br_netfilter
I0402 13:18:24.415783    2204 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0402 13:18:24.426622    2204 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0402 13:18:24.518973    2204 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0402 13:18:24.643998    2204 start.go:495] detecting cgroup driver to use...
I0402 13:18:24.644026    2204 detect.go:190] detected "systemd" cgroup driver on host os
I0402 13:18:24.644054    2204 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0402 13:18:24.669220    2204 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0402 13:18:24.669255    2204 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0402 13:18:24.687878    2204 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0402 13:18:24.708950    2204 ssh_runner.go:195] Run: which cri-dockerd
I0402 13:18:24.714028    2204 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0402 13:18:24.725177    2204 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (190 bytes)
I0402 13:18:24.749435    2204 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0402 13:18:24.842177    2204 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0402 13:18:24.936251    2204 docker.go:574] configuring docker to use "systemd" as cgroup driver...
I0402 13:18:24.936322    2204 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (129 bytes)
I0402 13:18:24.957994    2204 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0402 13:18:25.044341    2204 ssh_runner.go:195] Run: sudo systemctl restart docker
I0402 13:18:27.258820    2204 ssh_runner.go:235] Completed: sudo systemctl restart docker: (2.214460997s)
I0402 13:18:27.258853    2204 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I0402 13:18:27.274192    2204 ssh_runner.go:195] Run: sudo systemctl stop cri-docker.socket
I0402 13:18:27.289274    2204 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0402 13:18:27.302693    2204 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0402 13:18:27.373788    2204 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0402 13:18:27.462814    2204 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0402 13:18:27.530620    2204 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0402 13:18:27.564382    2204 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0402 13:18:27.578641    2204 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0402 13:18:27.650694    2204 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I0402 13:18:28.087423    2204 start.go:542] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0402 13:18:28.087490    2204 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0402 13:18:28.093048    2204 start.go:563] Will wait 60s for crictl version
I0402 13:18:28.093210    2204 ssh_runner.go:195] Run: which crictl
I0402 13:18:28.098113    2204 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0402 13:18:28.350820    2204 start.go:579] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  27.4.1
RuntimeApiVersion:  v1
I0402 13:18:28.350858    2204 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0402 13:18:28.527783    2204 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0402 13:18:28.575487    2204 out.go:235] 🐳  Preparing Kubernetes v1.32.0 on Docker 27.4.1 ...
I0402 13:18:28.575674    2204 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0402 13:18:28.608642    2204 ssh_runner.go:195] Run: grep 192.168.49.1	host.minikube.internal$ /etc/hosts
I0402 13:18:28.614699    2204 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.49.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0402 13:18:28.630283    2204 kubeadm.go:883] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true ingress:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/debiann:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I0402 13:18:28.630350    2204 preload.go:131] Checking if preload exists for k8s version v1.32.0 and runtime docker
I0402 13:18:28.630381    2204 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0402 13:18:28.658760    2204 docker.go:689] Got preloaded images: -- stdout --
luxdeveloper7/dlopuha_application:latest
registry.k8s.io/kube-apiserver:v1.32.0
registry.k8s.io/kube-scheduler:v1.32.0
registry.k8s.io/kube-controller-manager:v1.32.0
registry.k8s.io/kube-proxy:v1.32.0
registry.k8s.io/ingress-nginx/controller:<none>
registry.k8s.io/ingress-nginx/kube-webhook-certgen:<none>
busybox:latest
registry.k8s.io/etcd:3.5.16-0
registry.k8s.io/coredns/coredns:v1.11.3
registry.k8s.io/pause:3.10
mongo:4.4
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0402 13:18:28.658769    2204 docker.go:619] Images already preloaded, skipping extraction
I0402 13:18:28.658806    2204 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0402 13:18:28.683528    2204 docker.go:689] Got preloaded images: -- stdout --
luxdeveloper7/dlopuha_application:latest
registry.k8s.io/kube-apiserver:v1.32.0
registry.k8s.io/kube-controller-manager:v1.32.0
registry.k8s.io/kube-scheduler:v1.32.0
registry.k8s.io/kube-proxy:v1.32.0
registry.k8s.io/ingress-nginx/controller:<none>
registry.k8s.io/ingress-nginx/kube-webhook-certgen:<none>
busybox:latest
registry.k8s.io/etcd:3.5.16-0
registry.k8s.io/coredns/coredns:v1.11.3
registry.k8s.io/pause:3.10
mongo:4.4
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0402 13:18:28.683538    2204 cache_images.go:84] Images are preloaded, skipping loading
I0402 13:18:28.683544    2204 kubeadm.go:934] updating node { 192.168.49.2 8443 v1.32.0 docker true true} ...
I0402 13:18:28.683700    2204 kubeadm.go:946] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.32.0/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I0402 13:18:28.683739    2204 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0402 13:18:29.064071    2204 cni.go:84] Creating CNI manager for ""
I0402 13:18:29.064081    2204 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0402 13:18:29.064180    2204 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I0402 13:18:29.064193    2204 kubeadm.go:189] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.32.0 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0402 13:18:29.064284    2204 kubeadm.go:195] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta4
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    - name: "node-ip"
      value: "192.168.49.2"
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    - name: "enable-admission-plugins"
      value: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    - name: "allocate-node-cidrs"
      value: "true"
    - name: "leader-elect"
      value: "false"
scheduler:
  extraArgs:
    - name: "leader-elect"
      value: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      - name: "proxy-refresh-interval"
        value: "70000"
kubernetesVersion: v1.32.0
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0402 13:18:29.064324    2204 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.32.0
I0402 13:18:29.078342    2204 binaries.go:44] Found k8s binaries, skipping transfer
I0402 13:18:29.078371    2204 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0402 13:18:29.088820    2204 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (307 bytes)
I0402 13:18:29.110917    2204 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0402 13:18:29.132804    2204 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2285 bytes)
I0402 13:18:29.157429    2204 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0402 13:18:29.162751    2204 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0402 13:18:29.177915    2204 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0402 13:18:29.246432    2204 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0402 13:18:29.278390    2204 certs.go:68] Setting up /home/debiann/.minikube/profiles/minikube for IP: 192.168.49.2
I0402 13:18:29.278398    2204 certs.go:194] generating shared ca certs ...
I0402 13:18:29.278407    2204 certs.go:226] acquiring lock for ca certs: {Name:mk79b0d84a18ebe62dba4c6fc04d6f8e71ded2fd Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0402 13:18:29.279181    2204 certs.go:235] skipping valid "minikubeCA" ca cert: /home/debiann/.minikube/ca.key
I0402 13:18:29.279986    2204 certs.go:235] skipping valid "proxyClientCA" ca cert: /home/debiann/.minikube/proxy-client-ca.key
I0402 13:18:29.279994    2204 certs.go:256] generating profile certs ...
I0402 13:18:29.280608    2204 certs.go:359] skipping valid signed profile cert regeneration for "minikube-user": /home/debiann/.minikube/profiles/minikube/client.key
I0402 13:18:29.281193    2204 certs.go:359] skipping valid signed profile cert regeneration for "minikube": /home/debiann/.minikube/profiles/minikube/apiserver.key.7fb57e3c
I0402 13:18:29.281913    2204 certs.go:359] skipping valid signed profile cert regeneration for "aggregator": /home/debiann/.minikube/profiles/minikube/proxy-client.key
I0402 13:18:29.282026    2204 certs.go:484] found cert: /home/debiann/.minikube/certs/ca-key.pem (1675 bytes)
I0402 13:18:29.282057    2204 certs.go:484] found cert: /home/debiann/.minikube/certs/ca.pem (1082 bytes)
I0402 13:18:29.282076    2204 certs.go:484] found cert: /home/debiann/.minikube/certs/cert.pem (1123 bytes)
I0402 13:18:29.282093    2204 certs.go:484] found cert: /home/debiann/.minikube/certs/key.pem (1679 bytes)
I0402 13:18:29.282423    2204 ssh_runner.go:362] scp /home/debiann/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0402 13:18:29.318306    2204 ssh_runner.go:362] scp /home/debiann/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0402 13:18:29.364685    2204 ssh_runner.go:362] scp /home/debiann/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0402 13:18:29.402545    2204 ssh_runner.go:362] scp /home/debiann/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0402 13:18:29.444190    2204 ssh_runner.go:362] scp /home/debiann/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1411 bytes)
I0402 13:18:29.491113    2204 ssh_runner.go:362] scp /home/debiann/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0402 13:18:29.535460    2204 ssh_runner.go:362] scp /home/debiann/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0402 13:18:29.574888    2204 ssh_runner.go:362] scp /home/debiann/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0402 13:18:29.611656    2204 ssh_runner.go:362] scp /home/debiann/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0402 13:18:29.651795    2204 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0402 13:18:29.676872    2204 ssh_runner.go:195] Run: openssl version
I0402 13:18:29.695136    2204 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0402 13:18:29.710754    2204 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0402 13:18:29.716950    2204 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Mar 24 10:02 /usr/share/ca-certificates/minikubeCA.pem
I0402 13:18:29.716982    2204 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0402 13:18:29.729113    2204 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0402 13:18:29.741471    2204 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I0402 13:18:29.747119    2204 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0402 13:18:29.756787    2204 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0402 13:18:29.772373    2204 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0402 13:18:29.784401    2204 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0402 13:18:29.794660    2204 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0402 13:18:29.803982    2204 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0402 13:18:29.814891    2204 kubeadm.go:392] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.46@sha256:fd2d445ddcc33ebc5c6b68a17e6219ea207ce63c005095ea1525296da2d1a279 Memory:2200 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.32.0 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true ingress:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/debiann:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0402 13:18:29.814961    2204 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0402 13:18:29.868297    2204 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0402 13:18:29.884349    2204 kubeadm.go:408] found existing configuration files, will attempt cluster restart
I0402 13:18:29.884356    2204 kubeadm.go:593] restartPrimaryControlPlane start ...
I0402 13:18:29.884387    2204 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0402 13:18:29.900114    2204 kubeadm.go:130] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0402 13:18:29.904471    2204 kubeconfig.go:125] found "minikube" server: "https://192.168.49.2:8443"
I0402 13:18:29.937409    2204 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0402 13:18:29.957457    2204 kubeadm.go:630] The running cluster does not require reconfiguration: 192.168.49.2
I0402 13:18:29.957479    2204 kubeadm.go:597] duration metric: took 73.119497ms to restartPrimaryControlPlane
I0402 13:18:29.957486    2204 kubeadm.go:394] duration metric: took 142.603553ms to StartCluster
I0402 13:18:29.957498    2204 settings.go:142] acquiring lock: {Name:mke53aef668e347e506210ee639483ca9dd69bc3 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0402 13:18:29.957669    2204 settings.go:150] Updating kubeconfig:  /home/debiann/.kube/config
I0402 13:18:29.960190    2204 lock.go:35] WriteFile acquiring /home/debiann/.kube/config: {Name:mk02795428dcace041d8da8c275e2acd56ed7a02 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0402 13:18:29.960495    2204 start.go:235] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.32.0 ContainerRuntime:docker ControlPlane:true Worker:true}
I0402 13:18:29.961200    2204 addons.go:511] enable addons start: toEnable=map[ambassador:false amd-gpu-device-plugin:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false inaccel:false ingress:true ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volcano:false volumesnapshots:false yakd:false]
I0402 13:18:29.961244    2204 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0402 13:18:29.961253    2204 addons.go:238] Setting addon storage-provisioner=true in "minikube"
W0402 13:18:29.961256    2204 addons.go:247] addon storage-provisioner should already be in state true
I0402 13:18:29.961273    2204 host.go:66] Checking if "minikube" exists ...
I0402 13:18:29.961454    2204 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.32.0
I0402 13:18:29.961478    2204 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0402 13:18:29.961492    2204 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0402 13:18:29.961529    2204 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0402 13:18:29.961666    2204 addons.go:69] Setting ingress=true in profile "minikube"
I0402 13:18:29.961672    2204 addons.go:238] Setting addon ingress=true in "minikube"
W0402 13:18:29.961675    2204 addons.go:247] addon ingress should already be in state true
I0402 13:18:29.961695    2204 host.go:66] Checking if "minikube" exists ...
I0402 13:18:29.961822    2204 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0402 13:18:29.961897    2204 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0402 13:18:29.964205    2204 out.go:177] 🔎  Verifying Kubernetes components...
I0402 13:18:29.971701    2204 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0402 13:18:30.027418    2204 out.go:177]     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0402 13:18:30.033137    2204 addons.go:435] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0402 13:18:30.033146    2204 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0402 13:18:30.033190    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:30.051851    2204 out.go:177]     ▪ Using image registry.k8s.io/ingress-nginx/controller:v1.11.3
I0402 13:18:30.064719    2204 out.go:177]     ▪ Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.4
I0402 13:18:30.069261    2204 out.go:177]     ▪ Using image registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.4
I0402 13:18:30.070845    2204 addons.go:238] Setting addon default-storageclass=true in "minikube"
W0402 13:18:30.070851    2204 addons.go:247] addon default-storageclass should already be in state true
I0402 13:18:30.070870    2204 host.go:66] Checking if "minikube" exists ...
I0402 13:18:30.071108    2204 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0402 13:18:30.072881    2204 addons.go:435] installing /etc/kubernetes/addons/ingress-deploy.yaml
I0402 13:18:30.072889    2204 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/ingress-deploy.yaml (16078 bytes)
I0402 13:18:30.072918    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:30.075368    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:30.096358    2204 addons.go:435] installing /etc/kubernetes/addons/storageclass.yaml
I0402 13:18:30.096367    2204 ssh_runner.go:362] scp storageclass/storageclass.yaml --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0402 13:18:30.096407    2204 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0402 13:18:30.110770    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:30.122188    2204 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/debiann/.minikube/machines/minikube/id_rsa Username:docker}
I0402 13:18:30.131451    2204 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0402 13:18:30.157470    2204 api_server.go:52] waiting for apiserver process to appear ...
I0402 13:18:30.157511    2204 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0402 13:18:30.222760    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0402 13:18:30.251086    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/ingress-deploy.yaml
I0402 13:18:30.277832    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0402 13:18:30.658540    2204 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0402 13:18:30.791195    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:30.791211    2204 retry.go:31] will retry after 268.172784ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0402 13:18:30.791358    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:30.791476    2204 retry.go:31] will retry after 305.569683ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0402 13:18:30.793821    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:30.793829    2204 retry.go:31] will retry after 174.682038ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:30.968819    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0402 13:18:31.060214    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0402 13:18:31.071583    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.071598    2204 retry.go:31] will retry after 291.321804ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.098464    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml
I0402 13:18:31.157882    2204 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0402 13:18:31.194314    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.194329    2204 retry.go:31] will retry after 373.692961ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0402 13:18:31.235636    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.235651    2204 retry.go:31] will retry after 458.320174ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.367670    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0402 13:18:31.466193    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.466209    2204 retry.go:31] will retry after 739.580401ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.569749    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0402 13:18:31.657560    2204 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0402 13:18:31.694962    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml
W0402 13:18:31.730498    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.730513    2204 retry.go:31] will retry after 451.646669ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.730545    2204 api_server.go:72] duration metric: took 1.770035103s to wait for apiserver process to appear ...
I0402 13:18:31.730550    2204 api_server.go:88] waiting for apiserver healthz status ...
I0402 13:18:31.730560    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:31.730782    2204 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
W0402 13:18:31.862611    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:31.862626    2204 retry.go:31] will retry after 436.932513ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:32.182571    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0402 13:18:32.205945    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0402 13:18:32.230889    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:32.231168    2204 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0402 13:18:32.300640    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml
W0402 13:18:32.371690    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:32.371705    2204 retry.go:31] will retry after 1.000606183s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0402 13:18:32.371829    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:32.371836    2204 retry.go:31] will retry after 796.917ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0402 13:18:32.433936    2204 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:32.433964    2204 retry.go:31] will retry after 537.644942ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/ingress-deploy.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0402 13:18:32.737975    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:32.739513    2204 api_server.go:269] stopped: https://192.168.49.2:8443/healthz: Get "https://192.168.49.2:8443/healthz": dial tcp 192.168.49.2:8443: connect: connection refused
I0402 13:18:32.973250    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml
I0402 13:18:33.169426    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0402 13:18:33.231879    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:33.437393    2204 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0402 13:18:34.198512    2204 api_server.go:279] https://192.168.49.2:8443/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0402 13:18:34.198523    2204 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0402 13:18:34.198533    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:34.208069    2204 api_server.go:279] https://192.168.49.2:8443/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0402 13:18:34.208081    2204 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0402 13:18:34.231085    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:34.238241    2204 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[-]poststarthook/bootstrap-controller failed: reason withheld
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-status-local-available-controller ok
[+]poststarthook/apiservice-status-remote-available-controller ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[-]poststarthook/apiservice-discovery-controller failed: reason withheld
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0402 13:18:34.238253    2204 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/priority-and-fairness-config-producer failed: reason withheld
[-]poststarthook/bootstrap-controller failed: reason withheld
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-status-local-available-controller ok
[+]poststarthook/apiservice-status-remote-available-controller ok
[-]poststarthook/apiservice-registration-controller failed: reason withheld
[-]poststarthook/apiservice-discovery-controller failed: reason withheld
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0402 13:18:34.731420    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:34.737498    2204 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-status-local-available-controller ok
[+]poststarthook/apiservice-status-remote-available-controller ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-discovery-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0402 13:18:34.737508    2204 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-status-local-available-controller ok
[+]poststarthook/apiservice-status-remote-available-controller ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-discovery-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0402 13:18:35.231130    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:35.235006    2204 api_server.go:279] https://192.168.49.2:8443/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-status-local-available-controller ok
[+]poststarthook/apiservice-status-remote-available-controller ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-discovery-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0402 13:18:35.235016    2204 api_server.go:103] status: https://192.168.49.2:8443/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-status-local-available-controller ok
[+]poststarthook/apiservice-status-remote-available-controller ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-discovery-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0402 13:18:35.576893    2204 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/ingress-deploy.yaml: (2.603619197s)
I0402 13:18:35.576911    2204 addons.go:479] Verifying addon ingress=true in "minikube"
I0402 13:18:35.577472    2204 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: (2.408032875s)
I0402 13:18:35.577814    2204 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.32.0/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: (2.140409261s)
I0402 13:18:35.582244    2204 out.go:177] 🔎  Verifying ingress addon...
I0402 13:18:35.586459    2204 kapi.go:75] Waiting for pod with label "app.kubernetes.io/name=ingress-nginx" in ns "ingress-nginx" ...
I0402 13:18:35.595197    2204 kapi.go:86] Found 3 Pods for label selector app.kubernetes.io/name=ingress-nginx
I0402 13:18:35.595209    2204 kapi.go:107] duration metric: took 8.753639ms to wait for app.kubernetes.io/name=ingress-nginx ...
I0402 13:18:35.597836    2204 out.go:177] 🌟  Enabled addons: storage-provisioner, default-storageclass, ingress
I0402 13:18:35.600437    2204 addons.go:514] duration metric: took 5.639238336s for enable addons: enabled=[storage-provisioner default-storageclass ingress]
I0402 13:18:35.731627    2204 api_server.go:253] Checking apiserver healthz at https://192.168.49.2:8443/healthz ...
I0402 13:18:35.736475    2204 api_server.go:279] https://192.168.49.2:8443/healthz returned 200:
ok
I0402 13:18:35.737358    2204 api_server.go:141] control plane version: v1.32.0
I0402 13:18:35.737369    2204 api_server.go:131] duration metric: took 4.006815238s to wait for apiserver health ...
I0402 13:18:35.737374    2204 system_pods.go:43] waiting for kube-system pods to appear ...
I0402 13:18:35.743276    2204 system_pods.go:59] 7 kube-system pods found
I0402 13:18:35.743402    2204 system_pods.go:61] "coredns-668d6bf9bc-wlpsc" [e362ed8c-01d4-48c0-8fcb-c2583143cb64] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0402 13:18:35.743408    2204 system_pods.go:61] "etcd-minikube" [5d4e0b9a-ec59-4b71-b6c0-cfe9509d256d] Running / Ready:ContainersNotReady (containers with unready status: [etcd]) / ContainersReady:ContainersNotReady (containers with unready status: [etcd])
I0402 13:18:35.743412    2204 system_pods.go:61] "kube-apiserver-minikube" [08e45f8c-aa67-4dc9-8d9a-b855c4c96d8b] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0402 13:18:35.743415    2204 system_pods.go:61] "kube-controller-manager-minikube" [cedbd0c9-6ddc-484c-87f2-029921719ffc] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0402 13:18:35.743417    2204 system_pods.go:61] "kube-proxy-ddmlm" [a798e785-0e7c-4c9f-a76b-72622fd635ef] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0402 13:18:35.743420    2204 system_pods.go:61] "kube-scheduler-minikube" [2a83438d-dbf3-457a-9e36-07d9a8dbefa1] Running / Ready:ContainersNotReady (containers with unready status: [kube-scheduler]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-scheduler])
I0402 13:18:35.743422    2204 system_pods.go:61] "storage-provisioner" [64624a9f-fb51-4e21-b26c-def5331f91a6] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0402 13:18:35.743427    2204 system_pods.go:74] duration metric: took 6.048767ms to wait for pod list to return data ...
I0402 13:18:35.743434    2204 kubeadm.go:582] duration metric: took 5.782923622s to wait for: map[apiserver:true system_pods:true]
I0402 13:18:35.743442    2204 node_conditions.go:102] verifying NodePressure condition ...
I0402 13:18:35.748533    2204 node_conditions.go:122] node storage ephemeral capacity is 50303512Ki
I0402 13:18:35.748547    2204 node_conditions.go:123] node cpu capacity is 4
I0402 13:18:35.748555    2204 node_conditions.go:105] duration metric: took 5.110147ms to run NodePressure ...
I0402 13:18:35.748563    2204 start.go:241] waiting for startup goroutines ...
I0402 13:18:35.748566    2204 start.go:246] waiting for cluster config update ...
I0402 13:18:35.748573    2204 start.go:255] writing updated cluster config ...
I0402 13:18:35.748763    2204 ssh_runner.go:195] Run: rm -f paused
I0402 13:18:35.839432    2204 start.go:600] kubectl: 1.32.2, cluster: 1.32.0 (minor skew: 0)
I0402 13:18:35.842844    2204 out.go:177] 🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default


==> Docker <==
Apr 02 17:28:32 minikube cri-dockerd[1284]: time="2025-04-02T17:28:32Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [============>                                      ]  209.2MB/824.2MB"
Apr 02 17:28:42 minikube cri-dockerd[1284]: time="2025-04-02T17:28:42Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=============>                                     ]  230.2MB/824.2MB"
Apr 02 17:28:52 minikube cri-dockerd[1284]: time="2025-04-02T17:28:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [==============>                                    ]  244.8MB/824.2MB"
Apr 02 17:29:02 minikube cri-dockerd[1284]: time="2025-04-02T17:29:02Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===============>                                   ]  259.9MB/824.2MB"
Apr 02 17:29:12 minikube cri-dockerd[1284]: time="2025-04-02T17:29:12Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================>                                 ]  293.8MB/824.2MB"
Apr 02 17:29:22 minikube cri-dockerd[1284]: time="2025-04-02T17:29:22Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [======================>                            ]  375.9MB/824.2MB"
Apr 02 17:29:32 minikube cri-dockerd[1284]: time="2025-04-02T17:29:32Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [========================>                          ]  406.6MB/824.2MB"
Apr 02 17:29:42 minikube cri-dockerd[1284]: time="2025-04-02T17:29:42Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===========================>                       ]  445.3MB/824.2MB"
Apr 02 17:29:52 minikube cri-dockerd[1284]: time="2025-04-02T17:29:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [==============================>                    ]  494.7MB/824.2MB"
Apr 02 17:30:02 minikube cri-dockerd[1284]: time="2025-04-02T17:30:02Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [==============================>                    ]  496.8MB/824.2MB"
Apr 02 17:30:12 minikube cri-dockerd[1284]: time="2025-04-02T17:30:12Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [==============================>                    ]  501.7MB/824.2MB"
Apr 02 17:30:22 minikube cri-dockerd[1284]: time="2025-04-02T17:30:22Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===============================>                   ]  511.9MB/824.2MB"
Apr 02 17:30:32 minikube cri-dockerd[1284]: time="2025-04-02T17:30:32Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===============================>                   ]  515.2MB/824.2MB"
Apr 02 17:30:42 minikube cri-dockerd[1284]: time="2025-04-02T17:30:42Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===============================>                   ]  517.4MB/824.2MB"
Apr 02 17:30:52 minikube cri-dockerd[1284]: time="2025-04-02T17:30:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===============================>                   ]  521.1MB/824.2MB"
Apr 02 17:31:02 minikube cri-dockerd[1284]: time="2025-04-02T17:31:02Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===============================>                   ]  524.9MB/824.2MB"
Apr 02 17:31:12 minikube cri-dockerd[1284]: time="2025-04-02T17:31:12Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  528.1MB/824.2MB"
Apr 02 17:31:22 minikube cri-dockerd[1284]: time="2025-04-02T17:31:22Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  528.7MB/824.2MB"
Apr 02 17:31:32 minikube cri-dockerd[1284]: time="2025-04-02T17:31:32Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  528.7MB/824.2MB"
Apr 02 17:31:42 minikube cri-dockerd[1284]: time="2025-04-02T17:31:42Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  529.2MB/824.2MB"
Apr 02 17:31:52 minikube cri-dockerd[1284]: time="2025-04-02T17:31:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  529.8MB/824.2MB"
Apr 02 17:32:02 minikube cri-dockerd[1284]: time="2025-04-02T17:32:02Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  529.8MB/824.2MB"
Apr 02 17:32:12 minikube cri-dockerd[1284]: time="2025-04-02T17:32:12Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  532.4MB/824.2MB"
Apr 02 17:32:22 minikube cri-dockerd[1284]: time="2025-04-02T17:32:22Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  536.7MB/824.2MB"
Apr 02 17:32:32 minikube cri-dockerd[1284]: time="2025-04-02T17:32:32Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  538.3MB/824.2MB"
Apr 02 17:32:42 minikube cri-dockerd[1284]: time="2025-04-02T17:32:42Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  539.4MB/824.2MB"
Apr 02 17:32:52 minikube cri-dockerd[1284]: time="2025-04-02T17:32:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  541.5MB/824.2MB"
Apr 02 17:33:02 minikube cri-dockerd[1284]: time="2025-04-02T17:33:02Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================>                  ]  543.1MB/824.2MB"
Apr 02 17:33:12 minikube cri-dockerd[1284]: time="2025-04-02T17:33:12Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================================>                 ]  544.7MB/824.2MB"
Apr 02 17:33:22 minikube cri-dockerd[1284]: time="2025-04-02T17:33:22Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================================>                 ]  546.3MB/824.2MB"
Apr 02 17:33:32 minikube cri-dockerd[1284]: time="2025-04-02T17:33:32Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================================>                 ]  547.4MB/824.2MB"
Apr 02 17:33:44 minikube cri-dockerd[1284]: time="2025-04-02T17:33:44Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================================>                 ]  547.9MB/824.2MB"
Apr 02 17:33:52 minikube cri-dockerd[1284]: time="2025-04-02T17:33:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================================>                 ]  548.5MB/824.2MB"
Apr 02 17:34:02 minikube cri-dockerd[1284]: time="2025-04-02T17:34:02Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================================>                 ]  548.5MB/824.2MB"
Apr 02 17:34:12 minikube cri-dockerd[1284]: time="2025-04-02T17:34:12Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=================================>                 ]    549MB/824.2MB"
Apr 02 17:34:22 minikube cri-dockerd[1284]: time="2025-04-02T17:34:22Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===================================>               ]  577.5MB/824.2MB"
Apr 02 17:34:32 minikube cri-dockerd[1284]: time="2025-04-02T17:34:32Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=======================================>           ]  650.5MB/824.2MB"
Apr 02 17:34:42 minikube cri-dockerd[1284]: time="2025-04-02T17:34:42Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=========================================>         ]  681.1MB/824.2MB"
Apr 02 17:34:52 minikube cri-dockerd[1284]: time="2025-04-02T17:34:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [===========================================>       ]  709.1MB/824.2MB"
Apr 02 17:35:02 minikube cri-dockerd[1284]: time="2025-04-02T17:35:02Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [=============================================>     ]  745.1MB/824.2MB"
Apr 02 17:35:12 minikube cri-dockerd[1284]: time="2025-04-02T17:35:12Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Downloading [================================================>  ]  795.7MB/824.2MB"
Apr 02 17:35:22 minikube cri-dockerd[1284]: time="2025-04-02T17:35:22Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Extracting [=======>                                           ]  130.9MB/824.2MB"
Apr 02 17:35:47 minikube cri-dockerd[1284]: time="2025-04-02T17:35:47Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Extracting [======================>                            ]  365.4MB/824.2MB"
Apr 02 17:35:52 minikube cri-dockerd[1284]: time="2025-04-02T17:35:52Z" level=info msg="Pulling image devopshint/node-app:latest: e9889cb20e5c: Extracting [==================================>                ]    571MB/824.2MB"
Apr 02 17:36:00 minikube cri-dockerd[1284]: time="2025-04-02T17:36:00Z" level=info msg="Stop pulling image devopshint/node-app:latest: Status: Downloaded newer image for devopshint/node-app:latest"
Apr 02 18:08:49 minikube cri-dockerd[1284]: time="2025-04-02T18:08:49Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/b3c6af2f8330c17aad932e71fadf13ff55c05c38813019673ea500fd188f4b2b/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local Dlink options ndots:5]"
Apr 02 18:08:55 minikube cri-dockerd[1284]: time="2025-04-02T18:08:55Z" level=info msg="Stop pulling image devopshint/node-app:latest: Status: Image is up to date for devopshint/node-app:latest"
Apr 02 18:09:26 minikube dockerd[983]: time="2025-04-02T18:09:26.507173608Z" level=info msg="Container failed to exit within 30s of signal 15 - using the force" container=68a41946c2cd2fc428e273fe8778a106f944c62e41f50090a97ff80097d39bfb
Apr 02 18:09:26 minikube dockerd[983]: time="2025-04-02T18:09:26.545399309Z" level=info msg="ignoring event" container=68a41946c2cd2fc428e273fe8778a106f944c62e41f50090a97ff80097d39bfb module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Apr 02 18:09:26 minikube cri-dockerd[1284]: time="2025-04-02T18:09:26Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"nodejs-app-8c5d666f9-czb22_default\": unexpected command output nsenter: cannot open /proc/4620/ns/net: No such file or directory\n with error: exit status 1"
Apr 02 18:09:26 minikube dockerd[983]: time="2025-04-02T18:09:26.821638916Z" level=info msg="ignoring event" container=0b9ab511b2d3e15a1622fde76ea8b7e9d018e61c39a015a6b22d1898ada25649 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Apr 02 20:17:58 minikube dockerd[983]: time="2025-04-02T20:17:58.639886463Z" level=error msg="stream copy error: reading from a closed fifo"
Apr 02 20:17:58 minikube dockerd[983]: time="2025-04-02T20:17:58.644663228Z" level=error msg="Error running exec 97788bba76aa351a8237d2682ad8fa56636d2203fb9090ebadc1220a8073b460 in container: OCI runtime exec failed: exec failed: unable to start container process: exec: \"netstat\": executable file not found in $PATH: unknown"
Apr 02 20:17:58 minikube dockerd[983]: time="2025-04-02T20:17:58.651088327Z" level=error msg="failed to close container stdin" container=f81139ff4c84439ccec3a7de13f911af2f3cf1e12cfa6537848b24b315cdb6da error="NotFound: process does not exist 97788bba76aa351a8237d2682ad8fa56636d2203fb9090ebadc1220a8073b460: not found" module=libcontainerd namespace=moby
Apr 02 20:31:36 minikube cri-dockerd[1284]: time="2025-04-02T20:31:36Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/f83b4114e724dc04fc325ede18eb809cb79d92bc2c712bcdf7a81e9cff090116/resolv.conf as [nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local Dlink options ndots:5]"
Apr 02 20:31:38 minikube cri-dockerd[1284]: time="2025-04-02T20:31:38Z" level=info msg="Stop pulling image devopshint/node-app:latest: Status: Image is up to date for devopshint/node-app:latest"
Apr 02 20:32:09 minikube dockerd[983]: time="2025-04-02T20:32:09.273834300Z" level=info msg="Container failed to exit within 30s of signal 15 - using the force" container=f81139ff4c84439ccec3a7de13f911af2f3cf1e12cfa6537848b24b315cdb6da
Apr 02 20:32:09 minikube dockerd[983]: time="2025-04-02T20:32:09.310231353Z" level=info msg="ignoring event" container=f81139ff4c84439ccec3a7de13f911af2f3cf1e12cfa6537848b24b315cdb6da module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Apr 02 20:32:09 minikube cri-dockerd[1284]: time="2025-04-02T20:32:09Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"nodejs-app-78d495bc79-587tt_default\": unexpected command output nsenter: cannot open /proc/12979/ns/net: No such file or directory\n with error: exit status 1"
Apr 02 20:32:09 minikube dockerd[983]: time="2025-04-02T20:32:09.582997754Z" level=info msg="ignoring event" container=b3c6af2f8330c17aad932e71fadf13ff55c05c38813019673ea500fd188f4b2b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"


==> container status <==
CONTAINER           IMAGE                                                                                                                        CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
183cdf502edd1       devopshint/node-app@sha256:07efd4763fa7b96ca6227e88a126e3e9622708dde42f9afef1d31e166eec2c65                                  15 minutes ago      Running             nodejs-app                0                   f83b4114e724d       nodejs-app-84df4447dd-pxv9k
6042ab485271c       6e38f40d628db                                                                                                                3 hours ago         Running             storage-provisioner       24                  fcad5cb141dc3       storage-provisioner
79c18fe613338       ee44bc2368033                                                                                                                3 hours ago         Running             controller                6                   b390cb5ea5563       ingress-nginx-controller-56d7c84fd4-l948x
bc16d6bd71a54       c69fa2e9cbf5f                                                                                                                3 hours ago         Running             coredns                   7                   f314d72838eae       coredns-668d6bf9bc-wlpsc
36511885d4859       6e38f40d628db                                                                                                                3 hours ago         Exited              storage-provisioner       23                  fcad5cb141dc3       storage-provisioner
9df3e5b9f2279       040f9f8aac8cd                                                                                                                3 hours ago         Running             kube-proxy                7                   bce7799ace80c       kube-proxy-ddmlm
9962562baf25e       a9e7e6b294baf                                                                                                                3 hours ago         Running             etcd                      7                   009c2fd183e7a       etcd-minikube
c8d1ada83c60d       8cab3d2a8bd0f                                                                                                                3 hours ago         Running             kube-controller-manager   7                   3ec9752780894       kube-controller-manager-minikube
5790212c08ca0       a389e107f4ff1                                                                                                                3 hours ago         Running             kube-scheduler            7                   1b17de4d28e39       kube-scheduler-minikube
3ede29f32eb1e       c2e17b8d0f4a3                                                                                                                3 hours ago         Running             kube-apiserver            7                   0c9aa1d349ebf       kube-apiserver-minikube
11a2910d444d6       ee44bc2368033                                                                                                                2 days ago          Exited              controller                5                   0a12d9b0c4942       ingress-nginx-controller-56d7c84fd4-l948x
169353d8cdcd2       c69fa2e9cbf5f                                                                                                                2 days ago          Exited              coredns                   6                   64477e1438d0e       coredns-668d6bf9bc-wlpsc
f43a358eee8a3       040f9f8aac8cd                                                                                                                2 days ago          Exited              kube-proxy                6                   96dce994092a6       kube-proxy-ddmlm
d36fd98833e82       8cab3d2a8bd0f                                                                                                                2 days ago          Exited              kube-controller-manager   6                   e3257d177f60f       kube-controller-manager-minikube
5c25855d70e2f       a389e107f4ff1                                                                                                                2 days ago          Exited              kube-scheduler            6                   9621d697fcd07       kube-scheduler-minikube
2e8e16b49741e       a9e7e6b294baf                                                                                                                2 days ago          Exited              etcd                      6                   cd1ccbd3c66bb       etcd-minikube
0807017b60147       c2e17b8d0f4a3                                                                                                                2 days ago          Exited              kube-apiserver            6                   80232e388d487       kube-apiserver-minikube
b9203bd28726c       a62eeff05ba51                                                                                                                9 days ago          Exited              patch                     1                   8b9adcce470f2       ingress-nginx-admission-patch-6md4q
0a29c65d72399       registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:a9f03b34a3cbfbb26d103a14046ab2c5130a80c3d69d526ff8063d2b37b9fd3f   9 days ago          Exited              create                    0                   54435ba3d81a6       ingress-nginx-admission-create-b4wbx


==> controller_ingress [11a2910d444d] <==
I0331 10:10:17.705410       8 ssl.go:535] "loading tls certificate" path="/usr/local/certificates/cert" key="/usr/local/certificates/key"
I0331 10:10:17.726646       8 nginx.go:271] "Starting NGINX Ingress controller"
I0331 10:10:17.739022       8 event.go:377] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"ingress-nginx-controller", UID:"bc153db0-0874-4f27-a4eb-23f1c760f700", APIVersion:"v1", ResourceVersion:"3301", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/ingress-nginx-controller
I0331 10:10:17.741921       8 event.go:377] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"tcp-services", UID:"26ea328e-3aad-47df-a782-33b422aa159e", APIVersion:"v1", ResourceVersion:"3302", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/tcp-services
I0331 10:10:17.741984       8 event.go:377] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"udp-services", UID:"9f6a6f61-858f-4892-a182-ca9f5c32192f", APIVersion:"v1", ResourceVersion:"3303", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/udp-services
I0331 10:10:18.834400       8 store.go:440] "Found valid IngressClass" ingress="dlopuha/nginx" ingressclass="_"
I0331 10:10:18.834738       8 event.go:377] Event(v1.ObjectReference{Kind:"Ingress", Namespace:"dlopuha", Name:"nginx", UID:"2cbc96b7-821f-4418-b4f2-5ea093fea70d", APIVersion:"networking.k8s.io/v1", ResourceVersion:"22361", FieldPath:""}): type: 'Normal' reason: 'Sync' Scheduled for sync
I0331 10:10:18.931152       8 nginx.go:317] "Starting NGINX process"
I0331 10:10:18.931889       8 leaderelection.go:254] attempting to acquire leader lease ingress-nginx/ingress-nginx-leader...
I0331 10:10:18.932640       8 nginx.go:337] "Starting validation webhook" address=":8443" certPath="/usr/local/certificates/cert" keyPath="/usr/local/certificates/key"
W0331 10:10:18.935523       8 controller.go:1216] Service "dlopuha/application" does not have any active Endpoint.
I0331 10:10:18.935590       8 controller.go:193] "Configuration changes detected, backend reload required"
I0331 10:10:18.941611       8 leaderelection.go:268] successfully acquired lease ingress-nginx/ingress-nginx-leader
I0331 10:10:18.941678       8 status.go:85] "New leader elected" identity="ingress-nginx-controller-56d7c84fd4-l948x"
I0331 10:10:18.946587       8 status.go:219] "POD is not ready" pod="ingress-nginx/ingress-nginx-controller-56d7c84fd4-l948x" node="minikube"
I0331 10:10:18.950362       8 status.go:304] "updating Ingress status" namespace="dlopuha" ingress="nginx" currentValue=[{"ip":"192.168.49.2"}] newValue=[]
I0331 10:10:18.961861       8 event.go:377] Event(v1.ObjectReference{Kind:"Ingress", Namespace:"dlopuha", Name:"nginx", UID:"2cbc96b7-821f-4418-b4f2-5ea093fea70d", APIVersion:"networking.k8s.io/v1", ResourceVersion:"31646", FieldPath:""}): type: 'Normal' reason: 'Sync' Scheduled for sync
I0331 10:10:19.009179       8 controller.go:213] "Backend successfully reloaded"
I0331 10:10:19.009382       8 controller.go:224] "Initial sync, sleeping for 1 second"
I0331 10:10:19.009606       8 event.go:377] Event(v1.ObjectReference{Kind:"Pod", Namespace:"ingress-nginx", Name:"ingress-nginx-controller-56d7c84fd4-l948x", UID:"807266b5-2b7f-45c3-8caa-114857c0cd4d", APIVersion:"v1", ResourceVersion:"31592", FieldPath:""}): type: 'Normal' reason: 'RELOAD' NGINX reload triggered due to a change in configuration
W0331 10:10:22.733748       8 controller.go:1216] Service "dlopuha/application" does not have any active Endpoint.
W0331 10:10:26.069203       8 controller.go:1216] Service "dlopuha/application" does not have any active Endpoint.
W0331 10:10:29.401691       8 controller.go:1216] Service "dlopuha/application" does not have any active Endpoint.
I0331 10:11:18.949440       8 status.go:304] "updating Ingress status" namespace="dlopuha" ingress="nginx" currentValue=null newValue=[{"ip":"192.168.49.2"}]
I0331 10:11:18.954652       8 event.go:377] Event(v1.ObjectReference{Kind:"Ingress", Namespace:"dlopuha", Name:"nginx", UID:"2cbc96b7-821f-4418-b4f2-5ea093fea70d", APIVersion:"networking.k8s.io/v1", ResourceVersion:"31713", FieldPath:""}): type: 'Normal' reason: 'Sync' Scheduled for sync
I0331 10:11:45.211454       8 controller.go:193] "Configuration changes detected, backend reload required"
I0331 10:11:45.242716       8 controller.go:213] "Backend successfully reloaded"
I0331 10:11:45.243268       8 event.go:377] Event(v1.ObjectReference{Kind:"Pod", Namespace:"ingress-nginx", Name:"ingress-nginx-controller-56d7c84fd4-l948x", UID:"807266b5-2b7f-45c3-8caa-114857c0cd4d", APIVersion:"v1", ResourceVersion:"31592", FieldPath:""}): type: 'Normal' reason: 'RELOAD' NGINX reload triggered due to a change in configuration
I0331 10:24:18.946325       8 status.go:219] "POD is not ready" pod="ingress-nginx/ingress-nginx-controller-56d7c84fd4-l948x" node="minikube"
E0331 10:27:07.842698       8 leaderelection.go:436] error retrieving resource lock ingress-nginx/ingress-nginx-leader: Get "https://10.96.0.1:443/apis/coordination.k8s.io/v1/namespaces/ingress-nginx/leases/ingress-nginx-leader": context deadline exceeded
I0331 10:27:07.842740       8 leaderelection.go:297] failed to renew lease ingress-nginx/ingress-nginx-leader: timed out waiting for the condition
E0331 10:27:07.842920       8 status.go:104] "error running poll" err="timed out waiting for the condition"
I0331 10:27:07.842934       8 leaderelection.go:254] attempting to acquire leader lease ingress-nginx/ingress-nginx-leader...
W0331 10:27:07.871797       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.Ingress ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:27:07.871844       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.Secret ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:27:07.871913       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:27:07.871927       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.ConfigMap ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:27:07.872238       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:27:07.872520       8 queue.go:131] "requeuing" err="Get \"https://10.96.0.1:443/api/v1/namespaces/ingress-nginx/pods?labelSelector=app.kubernetes.io%2Fcomponent%3Dcontroller%2Capp.kubernetes.io%2Finstance%3Dingress-nginx%2Capp.kubernetes.io%2Fname%3Dingress-nginx%2Cgcp-auth-skip-secret%3Dtrue%2Cpod-template-hash%3D56d7c84fd4\": http2: client connection lost" key="&ObjectMeta{Name:sync status,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[]OwnerReference{},Finalizers:[],ManagedFields:[]ManagedFieldsEntry{},}"
I0331 10:27:07.936469       8 leaderelection.go:268] successfully acquired lease ingress-nginx/ingress-nginx-leader
E0331 10:27:30.582437       8 leaderelection.go:429] Failed to update lock optimitically: etcdserver: request timed out, falling back to slow path
E0331 10:27:30.582504       8 leaderelection.go:436] error retrieving resource lock ingress-nginx/ingress-nginx-leader: client rate limiter Wait returned an error: rate: Wait(n=1) would exceed context deadline
I0331 10:27:30.582994       8 leaderelection.go:297] failed to renew lease ingress-nginx/ingress-nginx-leader: timed out waiting for the condition
E0331 10:27:30.583730       8 status.go:104] "error running poll" err="timed out waiting for the condition"
I0331 10:27:30.583746       8 leaderelection.go:254] attempting to acquire leader lease ingress-nginx/ingress-nginx-leader...
E0331 10:27:30.762915       8 leaderelection.go:429] Failed to update lock optimitically: Operation cannot be fulfilled on leases.coordination.k8s.io "ingress-nginx-leader": the object has been modified; please apply your changes to the latest version and try again, falling back to slow path
I0331 10:27:30.778650       8 leaderelection.go:268] successfully acquired lease ingress-nginx/ingress-nginx-leader
W0331 10:56:19.092703       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.Secret ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:56:19.092810       8 queue.go:131] "requeuing" err="Get \"https://10.96.0.1:443/api/v1/namespaces/ingress-nginx/pods?labelSelector=app.kubernetes.io%2Fcomponent%3Dcontroller%2Capp.kubernetes.io%2Finstance%3Dingress-nginx%2Capp.kubernetes.io%2Fname%3Dingress-nginx%2Cgcp-auth-skip-secret%3Dtrue%2Cpod-template-hash%3D56d7c84fd4\": http2: client connection lost" key="&ObjectMeta{Name:sync status,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[]OwnerReference{},Finalizers:[],ManagedFields:[]ManagedFieldsEntry{},}"
E0331 10:56:19.092867       8 reflector.go:158] "Unhandled Error" err="k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: Failed to watch *v1.ConfigMap: Get \"https://10.96.0.1:443/api/v1/configmaps?allowWatchBookmarks=true&labelSelector=OWNER%21%3DTILLER&resourceVersion=32547&timeout=5m18s&timeoutSeconds=318&watch=true\": http2: client connection lost" logger="UnhandledError"
W0331 10:56:19.092889       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.IngressClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:56:19.092906       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.Ingress ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:56:19.092924       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:56:19.092936       8 reflector.go:484] k8s.io/client-go@v0.31.1/tools/cache/reflector.go:243: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:56:19.092962       8 leaderelection.go:436] error retrieving resource lock ingress-nginx/ingress-nginx-leader: Get "https://10.96.0.1:443/apis/coordination.k8s.io/v1/namespaces/ingress-nginx/leases/ingress-nginx-leader": http2: client connection lost
I0331 10:56:19.092971       8 leaderelection.go:297] failed to renew lease ingress-nginx/ingress-nginx-leader: timed out waiting for the condition
E0331 10:56:19.093333       8 queue.go:131] "requeuing" err="Get \"https://10.96.0.1:443/api/v1/namespaces/ingress-nginx/pods?labelSelector=app.kubernetes.io%2Fcomponent%3Dcontroller%2Capp.kubernetes.io%2Finstance%3Dingress-nginx%2Capp.kubernetes.io%2Fname%3Dingress-nginx%2Cgcp-auth-skip-secret%3Dtrue%2Cpod-template-hash%3D56d7c84fd4\": http2: client connection lost" key="&ObjectMeta{Name:sync status,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[]OwnerReference{},Finalizers:[],ManagedFields:[]ManagedFieldsEntry{},}"
E0331 10:56:19.093353       8 status.go:104] "error running poll" err="timed out waiting for the condition"
I0331 10:56:19.093362       8 leaderelection.go:254] attempting to acquire leader lease ingress-nginx/ingress-nginx-leader...
I0331 10:56:19.464607       8 leaderelection.go:268] successfully acquired lease ingress-nginx/ingress-nginx-leader


==> controller_ingress [79c18fe61333] <==
-------------------------------------------------------------------------------
NGINX Ingress controller
  Release:       v1.11.3
  Build:         0106de65cfccb74405a6dfa7d9daffc6f0a6ef1a
  Repository:    https://github.com/kubernetes/ingress-nginx
  nginx version: nginx/1.25.5

-------------------------------------------------------------------------------

W0402 17:18:36.976240       7 client_config.go:659] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
I0402 17:18:36.976515       7 main.go:205] "Creating API client" host="https://10.96.0.1:443"
W0402 17:19:08.055856       7 main.go:245] Initial connection to the Kubernetes API server was retried 1 times.
I0402 17:19:08.056030       7 main.go:248] "Running in Kubernetes cluster" major="1" minor="32" git="v1.32.0" state="clean" commit="70d3cc986aa8221cd1dfb1121852688902d3bf53" platform="linux/amd64"
I0402 17:19:08.092971       7 main.go:101] "SSL fake certificate created" file="/etc/ingress-controller/ssl/default-fake-certificate.pem"
I0402 17:19:08.131160       7 ssl.go:535] "loading tls certificate" path="/usr/local/certificates/cert" key="/usr/local/certificates/key"
I0402 17:19:08.147789       7 nginx.go:271] "Starting NGINX Ingress controller"
I0402 17:19:08.154697       7 event.go:377] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"ingress-nginx-controller", UID:"bc153db0-0874-4f27-a4eb-23f1c760f700", APIVersion:"v1", ResourceVersion:"3301", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/ingress-nginx-controller
I0402 17:19:08.160531       7 event.go:377] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"tcp-services", UID:"26ea328e-3aad-47df-a782-33b422aa159e", APIVersion:"v1", ResourceVersion:"3302", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/tcp-services
I0402 17:19:08.160617       7 event.go:377] Event(v1.ObjectReference{Kind:"ConfigMap", Namespace:"ingress-nginx", Name:"udp-services", UID:"9f6a6f61-858f-4892-a182-ca9f5c32192f", APIVersion:"v1", ResourceVersion:"3303", FieldPath:""}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/udp-services
I0402 17:19:09.351240       7 nginx.go:317] "Starting NGINX process"
I0402 17:19:09.351388       7 leaderelection.go:254] attempting to acquire leader lease ingress-nginx/ingress-nginx-leader...
I0402 17:19:09.352491       7 nginx.go:337] "Starting validation webhook" address=":8443" certPath="/usr/local/certificates/cert" keyPath="/usr/local/certificates/key"
I0402 17:19:09.352774       7 controller.go:193] "Configuration changes detected, backend reload required"
I0402 17:19:09.363570       7 leaderelection.go:268] successfully acquired lease ingress-nginx/ingress-nginx-leader
I0402 17:19:09.363736       7 status.go:85] "New leader elected" identity="ingress-nginx-controller-56d7c84fd4-l948x"
I0402 17:19:09.369962       7 status.go:219] "POD is not ready" pod="ingress-nginx/ingress-nginx-controller-56d7c84fd4-l948x" node="minikube"
I0402 17:19:09.428527       7 controller.go:213] "Backend successfully reloaded"
I0402 17:19:09.428677       7 controller.go:224] "Initial sync, sleeping for 1 second"
I0402 17:19:09.428803       7 event.go:377] Event(v1.ObjectReference{Kind:"Pod", Namespace:"ingress-nginx", Name:"ingress-nginx-controller-56d7c84fd4-l948x", UID:"807266b5-2b7f-45c3-8caa-114857c0cd4d", APIVersion:"v1", ResourceVersion:"32647", FieldPath:""}): type: 'Normal' reason: 'RELOAD' NGINX reload triggered due to a change in configuration
I0402 17:52:26.126573       7 status.go:219] "POD is not ready" pod="ingress-nginx/ingress-nginx-controller-56d7c84fd4-l948x" node="minikube"
E0402 18:04:22.881192       7 leaderelection.go:436] error retrieving resource lock ingress-nginx/ingress-nginx-leader: Get "https://10.96.0.1:443/apis/coordination.k8s.io/v1/namespaces/ingress-nginx/leases/ingress-nginx-leader": context deadline exceeded
I0402 18:04:22.885733       7 leaderelection.go:297] failed to renew lease ingress-nginx/ingress-nginx-leader: timed out waiting for the condition
I0402 18:04:22.890969       7 leaderelection.go:254] attempting to acquire leader lease ingress-nginx/ingress-nginx-leader...
E0402 18:04:22.955086       7 status.go:104] "error running poll" err="timed out waiting for the condition"
I0402 18:04:24.592552       7 leaderelection.go:268] successfully acquired lease ingress-nginx/ingress-nginx-leader


==> coredns [169353d8cdcd] <==
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 9e2996f8cb67ac53e0259ab1f8d615d07d1beb0bd07e6a1e39769c3bf486a905bb991cc47f8d2f14d0d3a90a87dfc625a0b4c524fed169d8158c40657c0694b1
CoreDNS-1.11.3
linux/amd64, go1.21.11, a6338e9
[INFO] 127.0.0.1:51239 - 49677 "HINFO IN 7842050750615014724.139141824373165689. udp 56 false 512" NXDOMAIN qr,rd,ra 131 0.028815096s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[1364226625]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (31-Mar-2025 10:09:46.266) (total time: 30007ms):
Trace[1364226625]: ---"Objects listed" error:Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30007ms (10:10:16.273)
Trace[1364226625]: [30.007389135s] [30.007389135s] END
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[846841291]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (31-Mar-2025 10:09:46.267) (total time: 30007ms):
Trace[846841291]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30007ms (10:10:16.274)
Trace[846841291]: [30.007911756s] [30.007911756s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[787526957]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (31-Mar-2025 10:09:46.266) (total time: 30008ms):
Trace[787526957]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30007ms (10:10:16.274)
Trace[787526957]: [30.008330128s] [30.008330128s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] 10.244.0.37:60143 - 11003 "AAAA IN mongo.dlopuha.svc.cluster.local. udp 49 false 512" NOERROR qr,aa,rd 142 0.000422798s
[INFO] 10.244.0.37:60143 - 3577 "A IN mongo.dlopuha.svc.cluster.local. udp 49 false 512" NOERROR qr,aa,rd 96 0.000468082s
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: watch of *v1.Namespace ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: watch of *v1.Namespace ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding


==> coredns [bc16d6bd71a5] <==
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 9e2996f8cb67ac53e0259ab1f8d615d07d1beb0bd07e6a1e39769c3bf486a905bb991cc47f8d2f14d0d3a90a87dfc625a0b4c524fed169d8158c40657c0694b1
CoreDNS-1.11.3
linux/amd64, go1.21.11, a6338e9
[INFO] 127.0.0.1:46550 - 11434 "HINFO IN 1932614071070940913.8326700742733226404. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.037740071s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[154479020]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (02-Apr-2025 17:18:36.935) (total time: 30004ms):
Trace[154479020]: ---"Objects listed" error:Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30003ms (17:19:06.939)
Trace[154479020]: [30.004216765s] [30.004216765s] END
[INFO] plugin/kubernetes: Trace[1626219281]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (02-Apr-2025 17:18:36.935) (total time: 30004ms):
Trace[1626219281]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30004ms (17:19:06.939)
Trace[1626219281]: [30.004349776s] [30.004349776s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: Trace[261647833]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229 (02-Apr-2025 17:18:36.935) (total time: 30004ms):
Trace[261647833]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout 30004ms (17:19:06.939)
Trace[261647833]: [30.004592383s] [30.004592383s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.29.3/tools/cache/reflector.go:229: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout


==> describe nodes <==
Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=dd5d320e41b5451cdf3c01891bc4e13d189586ed-dirty
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2025_03_24T12_47_12_0700
                    minikube.k8s.io/version=v1.35.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Mon, 24 Mar 2025 16:47:08 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 02 Apr 2025 20:47:25 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 02 Apr 2025 20:44:53 +0000   Wed, 02 Apr 2025 18:04:34 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 02 Apr 2025 20:44:53 +0000   Wed, 02 Apr 2025 18:04:34 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 02 Apr 2025 20:44:53 +0000   Wed, 02 Apr 2025 18:04:34 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 02 Apr 2025 20:44:53 +0000   Wed, 02 Apr 2025 20:36:10 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  50303512Ki
  hugepages-2Mi:      0
  memory:             3959608Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  50303512Ki
  hugepages-2Mi:      0
  memory:             3959608Ki
  pods:               110
System Info:
  Machine ID:                 62ca62474fa349b793e88ecaf1faea49
  System UUID:                7d677115-aa20-4c23-a344-c64294d6f949
  Boot ID:                    ce3532b6-e199-46ec-bc84-0dd34af2f714
  Kernel Version:             6.1.0-32-amd64
  OS Image:                   Ubuntu 22.04.5 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://27.4.1
  Kubelet Version:            v1.32.0
  Kube-Proxy Version:         v1.32.0
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (9 in total)
  Namespace                   Name                                         CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                         ------------  ----------  ---------------  -------------  ---
  default                     nodejs-app-84df4447dd-pxv9k                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         15m
  ingress-nginx               ingress-nginx-controller-56d7c84fd4-l948x    100m (2%)     0 (0%)      90Mi (2%)        0 (0%)         9d
  kube-system                 coredns-668d6bf9bc-wlpsc                     100m (2%)     0 (0%)      70Mi (1%)        170Mi (4%)     9d
  kube-system                 etcd-minikube                                100m (2%)     0 (0%)      100Mi (2%)       0 (0%)         9d
  kube-system                 kube-apiserver-minikube                      250m (6%)     0 (0%)      0 (0%)           0 (0%)         9d
  kube-system                 kube-controller-manager-minikube             200m (5%)     0 (0%)      0 (0%)           0 (0%)         9d
  kube-system                 kube-proxy-ddmlm                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         9d
  kube-system                 kube-scheduler-minikube                      100m (2%)     0 (0%)      0 (0%)           0 (0%)         9d
  kube-system                 storage-provisioner                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         9d
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (21%)  0 (0%)
  memory             260Mi (6%)  170Mi (4%)
  ephemeral-storage  0 (0%)      0 (0%)
  hugepages-2Mi      0 (0%)      0 (0%)
Events:
  Type    Reason        Age                  From     Message
  ----    ------        ----                 ----     -------
  Normal  NodeNotReady  11m (x4 over 163m)   kubelet  Node minikube status is now: NodeNotReady
  Normal  NodeReady     11m (x6 over 3h28m)  kubelet  Node minikube status is now: NodeReady


==> dmesg <==
[  +0.000003] rcu: 	Possible timer handling issue on cpu=0 timer-softirq=215365
[  +0.000002] rcu: rcu_preempt kthread starved for 19797 jiffies! g601657 f0x0 RCU_GP_WAIT_FQS(5) ->state=0x402 ->cpu=0
[  +0.000003] rcu: 	Unless rcu_preempt kthread gets sufficient CPU time, OOM is now expected behavior.
[  +0.000002] rcu: RCU grace-period kthread stack dump:
[  +0.000111] rcu: Stack dump where RCU GP kthread last ran:
[  +0.000098] NMI backtrace for cpu 0
[  +0.000002] CPU: 0 PID: 33675 Comm: StreamTrans #2 Tainted: G           OE      6.1.0-32-amd64 #1  Debian 6.1.129-1
[  +0.000003] Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
[  +0.000001] RIP: 0033:0x7fb978d55c62
[  +0.000005] Code: 00 00 00 0f 1f 44 00 00 48 83 ec 08 48 83 c7 08 e8 23 ff ff ff 31 c0 48 83 c4 08 c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 41 54 <55> 48 83 ec 08 48 8b 07 8b 08 48 8d 50 08 48 8d 44 c8 08 48 39 c2
[  +0.000001] RSP: 002b:00007fb972b82890 EFLAGS: 00010206
[  +0.000002] RAX: 00007fb985371b18 RBX: 00007fb972b82900 RCX: 00007fb972b82900
[  +0.000001] RDX: 00007fb985371b18 RSI: 00007fb973013200 RDI: 00007fb985371ab8
[  +0.000001] RBP: 00007fb985371a90 R08: 000014258b829880 R09: 00000c9d8225edef
[  +0.000000] R10: 00007fff0abf9080 R11: 00000000002d604c R12: 00007fb985371a70
[  +0.000001] R13: 0000000000000000 R14: 00000006fc23ac00 R15: 0000000000000001
[  +0.000001] FS:  00007fb972b836c0 GS:  0000000000000000
[  +0.000966] CPU: 1 PID: 0 Comm: swapper/1 Tainted: G           OE      6.1.0-32-amd64 #1  Debian 6.1.129-1
[  +0.000005] Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
[  +0.000001] RIP: 0010:native_safe_halt+0xb/0x10
[  +0.000005] Code: 80 48 02 20 48 8b 00 a8 08 75 c0 e9 7c ff ff ff cc cc cc cc cc cc cc cc cc cc cc cc cc cc cc eb 07 0f 00 2d 79 30 5c 00 fb f4 <e9> 00 b1 3b 00 eb 07 0f 00 2d 69 30 5c 00 f4 e9 f1 b0 3b 00 cc 0f
[  +0.000002] RSP: 0018:ffffa5594009bed8 EFLAGS: 00010212
[  +0.000003] RAX: ffffffff8a646520 RBX: ffff962640289840 RCX: ffff9625bae30400
[  +0.000019] RDX: 4000000000000000 RSI: 0000000000000001 RDI: 000000000490b78c
[  +0.000001] RBP: 0000000000000001 R08: 00001407f979654f R09: 0000000000000000
[  +0.000002] R10: 00000000fffffffb R11: 0000000000000000 R12: 0000000000000000
[  +0.000001] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
[  +0.000001] FS:  0000000000000000(0000) GS:ffff962658c80000(0000) knlGS:0000000000000000
[  +0.000002] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[  +0.000001] CR2: 00007f0046d16010 CR3: 00000000507a0000 CR4: 00000000000106e0
[  +0.000002] Call Trace:
[  +0.000002]  <IRQ>
[  +0.000003]  ? rcu_dump_cpu_stacks+0xa4/0xe0
[  +0.000004]  ? rcu_sched_clock_irq.cold+0xe8/0x459
[  +0.000004]  ? srso_alias_return_thunk+0x5/0x7f
[  +0.000003]  ? timekeeping_update+0xdd/0x130
[  +0.000004]  ? srso_alias_return_thunk+0x5/0x7f
[  +0.000002]  ? srso_alias_return_thunk+0x5/0x7f
[  +0.000002]  ? timekeeping_advance+0x377/0x570
[  +0.000002]  ? update_process_times+0x70/0xb0
[  +0.000003]  ? tick_sched_handle+0x22/0x60
[  +0.000003]  ? tick_sched_timer+0x63/0x80
[  +0.000002]  ? tick_sched_do_timer+0xa0/0xa0
[  +0.000002]  ? __hrtimer_run_queues+0x112/0x2b0
[  +0.000012]  ? hrtimer_interrupt+0xf4/0x210
[  +0.000004]  ? __sysvec_apic_timer_interrupt+0x5d/0x110
[  +0.000004]  ? sysvec_apic_timer_interrupt+0x69/0x90
[  +0.000003]  </IRQ>
[  +0.000001]  <TASK>
[  +0.000001]  ? asm_sysvec_apic_timer_interrupt+0x16/0x20
[  +0.000004]  ? __sched_text_end+0x6/0x6
[  +0.000003]  ? native_safe_halt+0xb/0x10
[  +0.000002]  ? srso_alias_return_thunk+0x5/0x7f
[  +0.000002]  default_idle+0xa/0x10
[  +0.000002]  default_idle_call+0x38/0xf0
[  +0.000002]  do_idle+0x21b/0x2a0
[  +0.000005]  cpu_startup_entry+0x26/0x30
[  +0.000002]  start_secondary+0x12a/0x150
[  +0.000004]  secondary_startup_64_no_verify+0xe5/0xeb
[  +0.000006]  </TASK>


==> etcd [2e8e16b49741] <==
{"level":"warn","ts":"2025-03-31T10:27:07.916910Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"133.530077ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumes/\" range_end:\"/registry/persistentvolumes0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:07.916922Z","caller":"traceutil/trace.go:171","msg":"trace[1094355220] range","detail":"{range_begin:/registry/persistentvolumes/; range_end:/registry/persistentvolumes0; response_count:0; response_revision:32472; }","duration":"133.546951ms","start":"2025-03-31T10:27:07.783371Z","end":"2025-03-31T10:27:07.916918Z","steps":["trace[1094355220] 'agreement among raft nodes before linearized reading'  (duration: 107.917901ms)","trace[1094355220] 'get authentication metadata'  (duration: 25.611434ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917043Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"133.685255ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:07.917055Z","caller":"traceutil/trace.go:171","msg":"trace[1296797996] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:0; response_revision:32472; }","duration":"133.700086ms","start":"2025-03-31T10:27:07.783351Z","end":"2025-03-31T10:27:07.917051Z","steps":["trace[1296797996] 'agreement among raft nodes before linearized reading'  (duration: 107.93985ms)","trace[1296797996] 'get authentication metadata'  (duration: 25.719409ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917161Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"133.830901ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/csidrivers/\" range_end:\"/registry/csidrivers0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.917173Z","caller":"traceutil/trace.go:171","msg":"trace[1511210583] range","detail":"{range_begin:/registry/csidrivers/; range_end:/registry/csidrivers0; response_count:0; response_revision:32472; }","duration":"133.847084ms","start":"2025-03-31T10:27:07.783322Z","end":"2025-03-31T10:27:07.917169Z","steps":["trace[1511210583] 'agreement among raft nodes before linearized reading'  (duration: 107.970063ms)","trace[1511210583] 'get authentication metadata'  (duration: 25.860999ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917251Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"133.958292ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/horizontalpodautoscalers/\" range_end:\"/registry/horizontalpodautoscalers0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.917264Z","caller":"traceutil/trace.go:171","msg":"trace[359436944] range","detail":"{range_begin:/registry/horizontalpodautoscalers/; range_end:/registry/horizontalpodautoscalers0; response_count:0; response_revision:32472; }","duration":"133.973383ms","start":"2025-03-31T10:27:07.783285Z","end":"2025-03-31T10:27:07.917259Z","steps":["trace[359436944] 'agreement among raft nodes before linearized reading'  (duration: 108.007326ms)","trace[359436944] 'get authentication metadata'  (duration: 25.950956ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917328Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"134.058292ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/clusterrolebindings/\" range_end:\"/registry/clusterrolebindings0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:07.917338Z","caller":"traceutil/trace.go:171","msg":"trace[128923086] range","detail":"{range_begin:/registry/clusterrolebindings/; range_end:/registry/clusterrolebindings0; response_count:0; response_revision:32472; }","duration":"134.084429ms","start":"2025-03-31T10:27:07.783251Z","end":"2025-03-31T10:27:07.917335Z","steps":["trace[128923086] 'agreement among raft nodes before linearized reading'  (duration: 108.043266ms)","trace[128923086] 'get authentication metadata'  (duration: 26.019293ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917395Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"134.149201ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/apiregistration.k8s.io/apiservices/\" range_end:\"/registry/apiregistration.k8s.io/apiservices0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:07.917417Z","caller":"traceutil/trace.go:171","msg":"trace[1452485131] range","detail":"{range_begin:/registry/apiregistration.k8s.io/apiservices/; range_end:/registry/apiregistration.k8s.io/apiservices0; response_count:0; response_revision:32472; }","duration":"134.177871ms","start":"2025-03-31T10:27:07.783233Z","end":"2025-03-31T10:27:07.917410Z","steps":["trace[1452485131] 'agreement among raft nodes before linearized reading'  (duration: 108.062823ms)","trace[1452485131] 'get authentication metadata'  (duration: 26.082762ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917435Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"134.260578ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/podtemplates/\" range_end:\"/registry/podtemplates0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.917446Z","caller":"traceutil/trace.go:171","msg":"trace[2105847452] range","detail":"{range_begin:/registry/podtemplates/; range_end:/registry/podtemplates0; response_count:0; response_revision:32472; }","duration":"134.276491ms","start":"2025-03-31T10:27:07.783167Z","end":"2025-03-31T10:27:07.917443Z","steps":["trace[2105847452] 'agreement among raft nodes before linearized reading'  (duration: 108.13ms)","trace[2105847452] 'get authentication metadata'  (duration: 26.13125ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917561Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"133.14447ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/flowschemas/\" range_end:\"/registry/flowschemas0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:07.917574Z","caller":"traceutil/trace.go:171","msg":"trace[1005331720] range","detail":"{range_begin:/registry/flowschemas/; range_end:/registry/flowschemas0; response_count:0; response_revision:32472; }","duration":"133.166902ms","start":"2025-03-31T10:27:07.784403Z","end":"2025-03-31T10:27:07.917570Z","steps":["trace[1005331720] 'agreement among raft nodes before linearized reading'  (duration: 106.95585ms)","trace[1005331720] 'get authentication metadata'  (duration: 26.191775ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917630Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"134.015802ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods\" limit:1 ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.917641Z","caller":"traceutil/trace.go:171","msg":"trace[1346062290] range","detail":"{range_begin:/registry/pods; range_end:; response_count:0; response_revision:32472; }","duration":"134.030553ms","start":"2025-03-31T10:27:07.783607Z","end":"2025-03-31T10:27:07.917637Z","steps":["trace[1346062290] 'agreement among raft nodes before linearized reading'  (duration: 107.860224ms)","trace[1346062290] 'get authentication metadata'  (duration: 26.155508ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917695Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"134.108063ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/\" range_end:\"/registry/services/endpoints0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:07.917706Z","caller":"traceutil/trace.go:171","msg":"trace[37912992] range","detail":"{range_begin:/registry/services/endpoints/; range_end:/registry/services/endpoints0; response_count:0; response_revision:32472; }","duration":"134.122774ms","start":"2025-03-31T10:27:07.783579Z","end":"2025-03-31T10:27:07.917702Z","steps":["trace[37912992] 'agreement among raft nodes before linearized reading'  (duration: 107.891298ms)","trace[37912992] 'get authentication metadata'  (duration: 26.215853ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917772Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"134.263733ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/poddisruptionbudgets/\" range_end:\"/registry/poddisruptionbudgets0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.917783Z","caller":"traceutil/trace.go:171","msg":"trace[718373413] range","detail":"{range_begin:/registry/poddisruptionbudgets/; range_end:/registry/poddisruptionbudgets0; response_count:0; response_revision:32472; }","duration":"134.279965ms","start":"2025-03-31T10:27:07.783500Z","end":"2025-03-31T10:27:07.917780Z","steps":["trace[718373413] 'agreement among raft nodes before linearized reading'  (duration: 107.972082ms)","trace[718373413] 'get authentication metadata'  (duration: 26.293563ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.917911Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"132.727972ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/apiextensions.k8s.io/customresourcedefinitions/\" range_end:\"/registry/apiextensions.k8s.io/customresourcedefinitions0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.917927Z","caller":"traceutil/trace.go:171","msg":"trace[1264260309] range","detail":"{range_begin:/registry/apiextensions.k8s.io/customresourcedefinitions/; range_end:/registry/apiextensions.k8s.io/customresourcedefinitions0; response_count:0; response_revision:32472; }","duration":"132.751075ms","start":"2025-03-31T10:27:07.785171Z","end":"2025-03-31T10:27:07.917922Z","steps":["trace[1264260309] 'agreement among raft nodes before linearized reading'  (duration: 106.405933ms)","trace[1264260309] 'get authentication metadata'  (duration: 26.317583ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.918012Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"133.57618ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ingress/\" range_end:\"/registry/ingress0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.918023Z","caller":"traceutil/trace.go:171","msg":"trace[1259168686] range","detail":"{range_begin:/registry/ingress/; range_end:/registry/ingress0; response_count:0; response_revision:32472; }","duration":"133.594537ms","start":"2025-03-31T10:27:07.784425Z","end":"2025-03-31T10:27:07.918020Z","steps":["trace[1259168686] 'agreement among raft nodes before linearized reading'  (duration: 107.154952ms)","trace[1259168686] 'get authentication metadata'  (duration: 26.424434ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:07.918118Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"134.690276ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/runtimeclasses/\" range_end:\"/registry/runtimeclasses0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:07.918130Z","caller":"traceutil/trace.go:171","msg":"trace[2048821291] range","detail":"{range_begin:/registry/runtimeclasses/; range_end:/registry/runtimeclasses0; response_count:0; response_revision:32472; }","duration":"134.705657ms","start":"2025-03-31T10:27:07.783420Z","end":"2025-03-31T10:27:07.918126Z","steps":["trace[2048821291] 'agreement among raft nodes before linearized reading'  (duration: 107.863823ms)","trace[2048821291] 'get authentication metadata'  (duration: 26.825721ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:30.539218Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-31T10:27:07.942298Z","time spent":"22.596914765s","remote":"127.0.0.1:48216","response type":"/etcdserverpb.KV/Txn","request count":0,"request size":0,"response count":0,"response size":0,"request content":""}
{"level":"warn","ts":"2025-03-31T10:27:30.571177Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"22.629047949s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/minions/minikube\" limit:1 ","response":"range_response_count:1 size:5518"}
{"level":"info","ts":"2025-03-31T10:27:30.571220Z","caller":"traceutil/trace.go:171","msg":"trace[2044202005] range","detail":"{range_begin:/registry/minions/minikube; range_end:; response_count:1; response_revision:32476; }","duration":"22.629108815s","start":"2025-03-31T10:27:07.942103Z","end":"2025-03-31T10:27:30.571212Z","steps":["trace[2044202005] 'agreement among raft nodes before linearized reading'  (duration: 22.596920833s)","trace[2044202005] 'range keys from in-memory index tree'  (duration: 32.118103ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:30.571243Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-03-31T10:27:07.942098Z","time spent":"22.629139294s","remote":"127.0.0.1:43826","response type":"/etcdserverpb.KV/Range","request count":0,"request size":30,"response count":1,"response size":5542,"request content":"key:\"/registry/minions/minikube\" limit:1 "}
{"level":"warn","ts":"2025-03-31T10:27:30.659280Z","caller":"wal/wal.go:805","msg":"slow fdatasync","took":"22.716924371s","expected-duration":"1s"}
{"level":"info","ts":"2025-03-31T10:27:30.659787Z","caller":"traceutil/trace.go:171","msg":"trace[1841654708] linearizableReadLoop","detail":"{readStateIndex:39015; appliedIndex:39015; }","duration":"120.84772ms","start":"2025-03-31T10:27:30.538924Z","end":"2025-03-31T10:27:30.659771Z","steps":["trace[1841654708] 'read index received'  (duration: 120.844924ms)","trace[1841654708] 'applied index is now lower than readState.Index'  (duration: 2.105µs)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:30.659900Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"120.961012ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/\" range_end:\"/registry/masterleases0\" ","response":"range_response_count:1 size:134"}
{"level":"info","ts":"2025-03-31T10:27:30.659917Z","caller":"traceutil/trace.go:171","msg":"trace[2007873536] range","detail":"{range_begin:/registry/masterleases/; range_end:/registry/masterleases0; response_count:1; response_revision:32477; }","duration":"121.010953ms","start":"2025-03-31T10:27:30.538901Z","end":"2025-03-31T10:27:30.659912Z","steps":["trace[2007873536] 'agreement among raft nodes before linearized reading'  (duration: 120.920385ms)"],"step_count":1}
{"level":"info","ts":"2025-03-31T10:27:30.703356Z","caller":"traceutil/trace.go:171","msg":"trace[1600252146] transaction","detail":"{read_only:false; response_revision:32478; number_of_response:1; }","duration":"126.512482ms","start":"2025-03-31T10:27:30.576832Z","end":"2025-03-31T10:27:30.703345Z","steps":["trace[1600252146] 'process raft request'  (duration: 109.989483ms)","trace[1600252146] 'compare'  (duration: 16.241952ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:27:30.703634Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"126.678483ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumes/pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce\" limit:1 ","response":"range_response_count:1 size:1232"}
{"level":"info","ts":"2025-03-31T10:27:30.703663Z","caller":"traceutil/trace.go:171","msg":"trace[371426807] range","detail":"{range_begin:/registry/persistentvolumes/pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce; range_end:; response_count:1; response_revision:32479; }","duration":"126.729916ms","start":"2025-03-31T10:27:30.576925Z","end":"2025-03-31T10:27:30.703655Z","steps":["trace[371426807] 'agreement among raft nodes before linearized reading'  (duration: 126.642967ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-31T10:27:30.703794Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"139.72991ms","expected-duration":"100ms","prefix":"read-only range ","request":"limit:1 keys_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:30.703818Z","caller":"traceutil/trace.go:171","msg":"trace[655038899] range","detail":"{range_begin:; range_end:; response_count:0; response_revision:32479; }","duration":"139.761575ms","start":"2025-03-31T10:27:30.564051Z","end":"2025-03-31T10:27:30.703813Z","steps":["trace[655038899] 'agreement among raft nodes before linearized reading'  (duration: 139.717749ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-31T10:27:30.703928Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"157.173571ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ingressclasses/\" range_end:\"/registry/ingressclasses0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:30.703942Z","caller":"traceutil/trace.go:171","msg":"trace[1540444388] range","detail":"{range_begin:/registry/ingressclasses/; range_end:/registry/ingressclasses0; response_count:0; response_revision:32479; }","duration":"157.198441ms","start":"2025-03-31T10:27:30.546740Z","end":"2025-03-31T10:27:30.703938Z","steps":["trace[1540444388] 'agreement among raft nodes before linearized reading'  (duration: 157.172428ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-31T10:27:30.704022Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"157.335131ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/limitranges/\" range_end:\"/registry/limitranges0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:27:30.704034Z","caller":"traceutil/trace.go:171","msg":"trace[1481863924] range","detail":"{range_begin:/registry/limitranges/; range_end:/registry/limitranges0; response_count:0; response_revision:32479; }","duration":"157.352542ms","start":"2025-03-31T10:27:30.546678Z","end":"2025-03-31T10:27:30.704030Z","steps":["trace[1481863924] 'agreement among raft nodes before linearized reading'  (duration: 157.331432ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-31T10:27:30.704149Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"157.475538ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ranges/serviceips\" limit:1 ","response":"range_response_count:1 size:97602"}
{"level":"info","ts":"2025-03-31T10:27:30.704162Z","caller":"traceutil/trace.go:171","msg":"trace[366083378] range","detail":"{range_begin:/registry/ranges/serviceips; range_end:; response_count:1; response_revision:32479; }","duration":"157.494385ms","start":"2025-03-31T10:27:30.546664Z","end":"2025-03-31T10:27:30.704158Z","steps":["trace[366083378] 'agreement among raft nodes before linearized reading'  (duration: 157.423835ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-31T10:27:30.704356Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"157.693424ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/ranges/servicenodeports\" limit:1 ","response":"range_response_count:1 size:314"}
{"level":"info","ts":"2025-03-31T10:27:30.704377Z","caller":"traceutil/trace.go:171","msg":"trace[230918804] range","detail":"{range_begin:/registry/ranges/servicenodeports; range_end:; response_count:1; response_revision:32479; }","duration":"157.723948ms","start":"2025-03-31T10:27:30.546646Z","end":"2025-03-31T10:27:30.704370Z","steps":["trace[230918804] 'agreement among raft nodes before linearized reading'  (duration: 157.649058ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-31T10:27:30.704472Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"157.832277ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/prioritylevelconfigurations/\" range_end:\"/registry/prioritylevelconfigurations0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-03-31T10:27:30.704489Z","caller":"traceutil/trace.go:171","msg":"trace[1702712741] range","detail":"{range_begin:/registry/prioritylevelconfigurations/; range_end:/registry/prioritylevelconfigurations0; response_count:0; response_revision:32479; }","duration":"157.871234ms","start":"2025-03-31T10:27:30.546613Z","end":"2025-03-31T10:27:30.704484Z","steps":["trace[1702712741] 'agreement among raft nodes before linearized reading'  (duration: 157.841722ms)"],"step_count":1}
{"level":"warn","ts":"2025-03-31T10:56:18.977090Z","caller":"etcdserver/server.go:1198","msg":"failed to revoke lease","lease-id":"70cc95ebad9e923a","error":"etcdserver: request timed out"}
{"level":"warn","ts":"2025-03-31T10:56:18.997849Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"23m40.339029176s","expected-duration":"100ms","prefix":"","request":"header:<ID:8128036266959606378 > lease_revoke:<id:70cc95ebad9e923a>","response":"size:30"}
{"level":"warn","ts":"2025-03-31T10:56:19.289946Z","caller":"embed/config_logging.go:170","msg":"rejected connection on client endpoint","remote-addr":"127.0.0.1:39290","server-name":"","error":"EOF"}
{"level":"info","ts":"2025-03-31T10:56:19.437201Z","caller":"traceutil/trace.go:171","msg":"trace[1815817201] transaction","detail":"{read_only:false; response_revision:32594; number_of_response:1; }","duration":"141.009126ms","start":"2025-03-31T10:56:19.296182Z","end":"2025-03-31T10:56:19.437191Z","steps":["trace[1815817201] 'process raft request'  (duration: 108.186535ms)","trace[1815817201] 'compare'  (duration: 31.683611ms)"],"step_count":2}
{"level":"warn","ts":"2025-03-31T10:56:19.437309Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"104.716724ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/specs\" limit:1 ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2025-03-31T10:56:19.437326Z","caller":"traceutil/trace.go:171","msg":"trace[513038927] range","detail":"{range_begin:/registry/services/specs; range_end:; response_count:0; response_revision:32596; }","duration":"104.756919ms","start":"2025-03-31T10:56:19.332564Z","end":"2025-03-31T10:56:19.437321Z","steps":["trace[513038927] 'agreement among raft nodes before linearized reading'  (duration: 104.720267ms)"],"step_count":1}
{"level":"info","ts":"2025-03-31T10:56:19.456178Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":32466}
{"level":"info","ts":"2025-03-31T10:56:19.461151Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":32466,"took":"4.83512ms","hash":3495417352,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1515520,"current-db-size-in-use":"1.5 MB"}
{"level":"info","ts":"2025-03-31T10:56:19.461182Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":3495417352,"revision":32466,"compact-revision":32278}


==> etcd [9962562baf25] <==
{"level":"warn","ts":"2025-04-02T19:39:05.500021Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-04-02T19:39:05.135553Z","time spent":"364.466084ms","remote":"127.0.0.1:48102","response type":"/etcdserverpb.KV/Range","request count":0,"request size":68,"response count":0,"response size":30,"request content":"key:\"/registry/poddisruptionbudgets/\" range_end:\"/registry/poddisruptionbudgets0\" count_only:true "}
{"level":"warn","ts":"2025-04-02T19:39:05.500079Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"364.43521ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/serviceaccounts/kube-system/node-controller\" limit:1 ","response":"range_response_count:1 size:196"}
{"level":"info","ts":"2025-04-02T19:39:05.500088Z","caller":"traceutil/trace.go:171","msg":"trace[164727583] range","detail":"{range_begin:/registry/serviceaccounts/kube-system/node-controller; range_end:; response_count:1; response_revision:35771; }","duration":"364.4557ms","start":"2025-04-02T19:39:05.135630Z","end":"2025-04-02T19:39:05.500085Z","steps":["trace[164727583] 'agreement among raft nodes before linearized reading'  (duration: 356.774615ms)"],"step_count":1}
{"level":"warn","ts":"2025-04-02T19:39:05.500096Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-04-02T19:39:05.135626Z","time spent":"364.467661ms","remote":"127.0.0.1:47962","response type":"/etcdserverpb.KV/Range","request count":0,"request size":57,"response count":1,"response size":220,"request content":"key:\"/registry/serviceaccounts/kube-system/node-controller\" limit:1 "}
{"level":"warn","ts":"2025-04-02T19:39:05.500185Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"364.559963ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" limit:1 ","response":"range_response_count:1 size:504"}
{"level":"info","ts":"2025-04-02T19:39:05.500196Z","caller":"traceutil/trace.go:171","msg":"trace[692475002] range","detail":"{range_begin:/registry/leases/ingress-nginx/ingress-nginx-leader; range_end:; response_count:1; response_revision:35771; }","duration":"364.583718ms","start":"2025-04-02T19:39:05.135610Z","end":"2025-04-02T19:39:05.500193Z","steps":["trace[692475002] 'agreement among raft nodes before linearized reading'  (duration: 356.796938ms)"],"step_count":1}
{"level":"warn","ts":"2025-04-02T19:39:05.500205Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-04-02T19:39:05.135607Z","time spent":"364.595375ms","remote":"127.0.0.1:48040","response type":"/etcdserverpb.KV/Range","request count":0,"request size":55,"response count":1,"response size":528,"request content":"key:\"/registry/leases/ingress-nginx/ingress-nginx-leader\" limit:1 "}
{"level":"warn","ts":"2025-04-02T19:39:05.500255Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"364.649378ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/serviceaccounts/kube-system/generic-garbage-collector\" limit:1 ","response":"range_response_count:1 size:217"}
{"level":"info","ts":"2025-04-02T19:39:05.500274Z","caller":"traceutil/trace.go:171","msg":"trace[1485995842] range","detail":"{range_begin:/registry/serviceaccounts/kube-system/generic-garbage-collector; range_end:; response_count:1; response_revision:35771; }","duration":"364.669801ms","start":"2025-04-02T19:39:05.135591Z","end":"2025-04-02T19:39:05.500261Z","steps":["trace[1485995842] 'agreement among raft nodes before linearized reading'  (duration: 356.818381ms)"],"step_count":1}
{"level":"warn","ts":"2025-04-02T19:39:05.500285Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-04-02T19:39:05.135589Z","time spent":"364.693918ms","remote":"127.0.0.1:47962","response type":"/etcdserverpb.KV/Range","request count":0,"request size":67,"response count":1,"response size":241,"request content":"key:\"/registry/serviceaccounts/kube-system/generic-garbage-collector\" limit:1 "}
{"level":"warn","ts":"2025-04-02T19:39:05.500328Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"364.843613ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/leases/\" range_end:\"/registry/leases0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-04-02T19:39:05.500338Z","caller":"traceutil/trace.go:171","msg":"trace[47041871] range","detail":"{range_begin:/registry/leases/; range_end:/registry/leases0; response_count:0; response_revision:35771; }","duration":"364.866318ms","start":"2025-04-02T19:39:05.135469Z","end":"2025-04-02T19:39:05.500335Z","steps":["trace[47041871] 'agreement among raft nodes before linearized reading'  (duration: 356.948593ms)"],"step_count":1}
{"level":"warn","ts":"2025-04-02T19:39:05.500346Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-04-02T19:39:05.135467Z","time spent":"364.877191ms","remote":"127.0.0.1:48040","response type":"/etcdserverpb.KV/Range","request count":0,"request size":40,"response count":3,"response size":32,"request content":"key:\"/registry/leases/\" range_end:\"/registry/leases0\" count_only:true "}
{"level":"warn","ts":"2025-04-02T19:39:05.500401Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"364.842565ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/secrets/\" range_end:\"/registry/secrets0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-04-02T19:39:05.500412Z","caller":"traceutil/trace.go:171","msg":"trace[1771915370] range","detail":"{range_begin:/registry/secrets/; range_end:/registry/secrets0; response_count:0; response_revision:35771; }","duration":"364.870491ms","start":"2025-04-02T19:39:05.135539Z","end":"2025-04-02T19:39:05.500409Z","steps":["trace[1771915370] 'agreement among raft nodes before linearized reading'  (duration: 356.876184ms)"],"step_count":1}
{"level":"warn","ts":"2025-04-02T19:39:05.500422Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-04-02T19:39:05.135522Z","time spent":"364.897203ms","remote":"127.0.0.1:47852","response type":"/etcdserverpb.KV/Range","request count":0,"request size":42,"response count":1,"response size":32,"request content":"key:\"/registry/secrets/\" range_end:\"/registry/secrets0\" count_only:true "}
{"level":"info","ts":"2025-04-02T19:39:05.505348Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":35712,"took":"4.418125ms","hash":516666882,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1458176,"current-db-size-in-use":"1.5 MB"}
{"level":"info","ts":"2025-04-02T19:39:05.505377Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":516666882,"revision":35712,"compact-revision":35428}
{"level":"warn","ts":"2025-04-02T19:39:05.505466Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"370.977431ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/rolebindings/\" range_end:\"/registry/rolebindings0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2025-04-02T19:39:05.505483Z","caller":"traceutil/trace.go:171","msg":"trace[94315719] range","detail":"{range_begin:/registry/rolebindings/; range_end:/registry/rolebindings0; response_count:0; response_revision:35771; }","duration":"371.0043ms","start":"2025-04-02T19:39:05.134472Z","end":"2025-04-02T19:39:05.505476Z","steps":["trace[94315719] 'agreement among raft nodes before linearized reading'  (duration: 357.950174ms)"],"step_count":1}
{"level":"warn","ts":"2025-04-02T19:39:05.505499Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2025-04-02T19:39:05.134469Z","time spent":"371.0263ms","remote":"127.0.0.1:48120","response type":"/etcdserverpb.KV/Range","request count":0,"request size":52,"response count":14,"response size":32,"request content":"key:\"/registry/rolebindings/\" range_end:\"/registry/rolebindings0\" count_only:true "}
{"level":"info","ts":"2025-04-02T19:44:05.509567Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":35767}
{"level":"info","ts":"2025-04-02T19:44:05.514190Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":35767,"took":"4.395229ms","hash":3161100466,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1495040,"current-db-size-in-use":"1.5 MB"}
{"level":"info","ts":"2025-04-02T19:44:05.514222Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":3161100466,"revision":35767,"compact-revision":35712}
{"level":"info","ts":"2025-04-02T19:49:09.086523Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":36012}
{"level":"info","ts":"2025-04-02T19:49:09.093928Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":36012,"took":"7.271366ms","hash":1775313058,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1552384,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T19:49:09.093965Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":1775313058,"revision":36012,"compact-revision":35767}
{"level":"info","ts":"2025-04-02T19:54:25.308307Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":36259}
{"level":"info","ts":"2025-04-02T19:54:25.314477Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":36259,"took":"6.047996ms","hash":1111424437,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1515520,"current-db-size-in-use":"1.5 MB"}
{"level":"info","ts":"2025-04-02T19:54:25.314513Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":1111424437,"revision":36259,"compact-revision":36012}
{"level":"info","ts":"2025-04-02T19:59:25.324435Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":36521}
{"level":"info","ts":"2025-04-02T19:59:25.330173Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":36521,"took":"5.626281ms","hash":1830155357,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1572864,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T19:59:25.330232Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":1830155357,"revision":36521,"compact-revision":36259}
{"level":"info","ts":"2025-04-02T20:04:25.337796Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":36807}
{"level":"info","ts":"2025-04-02T20:04:25.344773Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":36807,"took":"6.808191ms","hash":832967109,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1601536,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T20:04:25.344858Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":832967109,"revision":36807,"compact-revision":36521}
{"level":"info","ts":"2025-04-02T20:09:25.346699Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":37087}
{"level":"info","ts":"2025-04-02T20:09:25.352870Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":37087,"took":"6.054837ms","hash":1830945342,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1564672,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T20:09:25.353010Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":1830945342,"revision":37087,"compact-revision":36807}
{"level":"info","ts":"2025-04-02T20:14:25.355636Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":37359}
{"level":"info","ts":"2025-04-02T20:14:25.361759Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":37359,"took":"5.997365ms","hash":1935044637,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1576960,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T20:14:25.361818Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":1935044637,"revision":37359,"compact-revision":37087}
{"level":"info","ts":"2025-04-02T20:19:25.363739Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":37630}
{"level":"info","ts":"2025-04-02T20:19:25.367798Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":37630,"took":"3.789694ms","hash":680394103,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1593344,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T20:19:25.367863Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":680394103,"revision":37630,"compact-revision":37359}
{"level":"info","ts":"2025-04-02T20:24:25.370647Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":37908}
{"level":"info","ts":"2025-04-02T20:24:25.373676Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":37908,"took":"2.906617ms","hash":2615433523,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1634304,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T20:24:25.373728Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":2615433523,"revision":37908,"compact-revision":37630}
{"level":"info","ts":"2025-04-02T20:29:41.234306Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":38188}
{"level":"info","ts":"2025-04-02T20:29:41.245089Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":38188,"took":"10.650713ms","hash":380903214,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1568768,"current-db-size-in-use":"1.6 MB"}
{"level":"info","ts":"2025-04-02T20:29:41.245121Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":380903214,"revision":38188,"compact-revision":37908}
{"level":"info","ts":"2025-04-02T20:36:00.510190Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":38424}
{"level":"info","ts":"2025-04-02T20:36:00.527103Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":38424,"took":"16.786226ms","hash":921208026,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1683456,"current-db-size-in-use":"1.7 MB"}
{"level":"info","ts":"2025-04-02T20:36:00.527140Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":921208026,"revision":38424,"compact-revision":38188}
{"level":"info","ts":"2025-04-02T20:41:00.534193Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":38753}
{"level":"info","ts":"2025-04-02T20:41:00.538844Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":38753,"took":"4.400022ms","hash":2516600498,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1916928,"current-db-size-in-use":"1.9 MB"}
{"level":"info","ts":"2025-04-02T20:41:00.539034Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":2516600498,"revision":38753,"compact-revision":38424}
{"level":"info","ts":"2025-04-02T20:46:00.546960Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":39033}
{"level":"info","ts":"2025-04-02T20:46:00.555346Z","caller":"mvcc/kvstore_compaction.go:72","msg":"finished scheduled compaction","compact-revision":39033,"took":"7.938317ms","hash":3690938677,"current-db-size-bytes":3686400,"current-db-size":"3.7 MB","current-db-size-in-use-bytes":1654784,"current-db-size-in-use":"1.7 MB"}
{"level":"info","ts":"2025-04-02T20:46:00.555428Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":3690938677,"revision":39033,"compact-revision":38753}


==> kernel <==
 20:47:26 up  4:02,  0 users,  load average: 0.33, 0.37, 0.33
Linux minikube 6.1.0-32-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.129-1 (2025-03-06) x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.5 LTS"


==> kube-apiserver [0807017b6014] <==
E0331 10:27:07.828069       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.829430       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.888489       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.895217       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0331 10:27:07.895310       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0331 10:27:07.896309       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.896458       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="69.921836ms" method="GET" path="/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath" result=null
E0331 10:27:07.898543       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.899302       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.899579       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.900675       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="4.959201ms" method="GET" path="/api/v1/namespaces/ingress-nginx/pods" result=null
E0331 10:27:07.901454       1 controller.go:195] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"apiserver-eqt674mfxb4j56mrjjkoe7b7ii\": the object has been modified; please apply your changes to the latest version and try again"
E0331 10:27:07.901555       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.906229       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:27:07.910289       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="14.998974ms" method="GET" path="/apis/coordination.k8s.io/v1/namespaces/ingress-nginx/leases/ingress-nginx-leader" result=null
E0331 10:27:30.541916       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: rpctypes.EtcdError{code:0xe, desc:\"etcdserver: request timed out\"}: etcdserver: request timed out" logger="UnhandledError"
W0331 10:56:19.080732       1 logging.go:55] [core] [Channel #266 SubChannel #267]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: i/o timeout"
E0331 10:56:19.085101       1 repair.go:165] "Unhandled Error" err="unable to refresh the service IP block: rpc error: code = Unavailable desc = keepalive ping failed to receive ACK within timeout" logger="UnhandledError"
E0331 10:56:19.201379       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0331 10:56:19.202512       1 wrap.go:53] "Timeout or abort while handling" logger="UnhandledError" method="GET" URI="/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath" auditID="692e28c0-1cd5-49f8-9f0f-1ba8eeb3a2aa"
E0331 10:56:19.202529       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="1.712µs" method="GET" path="/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath" result=null
E0331 10:56:19.208088       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.208438       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 333.281µs, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
E0331 10:56:19.209139       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.210186       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.211297       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="3.789207ms" method="POST" path="/api/v1/namespaces/default/events" result=null
E0331 10:56:19.219036       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0331 10:56:19.219518       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0331 10:56:19.219616       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0331 10:56:19.220364       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.220585       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.220688       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.221387       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.221659       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.221712       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.222410       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.222708       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.222731       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.223547       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="4.788119ms" method="GET" path="/api/v1/namespaces/ingress-nginx/pods" result=null
E0331 10:56:19.223772       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="4.173664ms" method="GET" path="/api/v1/namespaces/ingress-nginx/pods" result=null
E0331 10:56:19.226760       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="7.267658ms" method="GET" path="/apis/coordination.k8s.io/v1/namespaces/ingress-nginx/leases/ingress-nginx-leader" result=null
E0331 10:56:19.245546       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.246161       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.246626       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.246642       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.247234       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.247678       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.250181       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="7.974925ms" method="POST" path="/api/v1/namespaces/kube-system/events" result=null
E0331 10:56:19.250243       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 45.464µs, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
E0331 10:56:19.250257       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 4.690191ms, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
E0331 10:56:19.250264       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 4.090133ms, panicked: false, err: context canceled, panic-reason: <nil>" logger="UnhandledError"
E0331 10:56:19.250273       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.250288       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.251292       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0331 10:56:19.251327       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="9.064675ms" method="PUT" path="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube" result=null
E0331 10:56:19.252431       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="10.125656ms" method="PATCH" path="/api/v1/nodes/minikube/status" result=null
E0331 10:56:19.253708       1 repair.go:127] "Unhandled Error" err="unable to refresh the service IP block: context deadline exceeded" logger="UnhandledError"
E0331 10:56:19.367391       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-03-31 10:56:19.367379279" prevR="26.05767595ss" incrR="184467440737.09549640ss" currentR="26.05765619ss"
E0331 10:56:19.409601       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-03-31 10:56:19.409588898" prevR="26.08580149ss" incrR="184467440737.09549921ss" currentR="26.08578454ss"
E0331 10:56:19.456456       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-low" when="2025-03-31 10:56:19.456439974" prevR="35.27467788ss" incrR="184467440737.09549466ss" currentR="35.27465638ss"


==> kube-apiserver [3ede29f32eb1] <==
I0402 17:18:34.293677       1 cache.go:39] Caches are synced for RemoteAvailability controller
I0402 17:18:34.298600       1 shared_informer.go:320] Caches are synced for crd-autoregister
I0402 17:18:34.298615       1 aggregator.go:171] initial CRD sync complete...
I0402 17:18:34.298620       1 autoregister_controller.go:144] Starting autoregister controller
I0402 17:18:34.298624       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0402 17:18:34.298628       1 cache.go:39] Caches are synced for autoregister controller
E0402 17:18:34.314071       1 controller.go:97] Error removing old endpoints from kubernetes service: no API server IP addresses were listed in storage, refusing to erase all endpoints for the kubernetes Service
I0402 17:18:34.319926       1 controller.go:615] quota admission added evaluator for: leases.coordination.k8s.io
E0402 17:18:34.327975       1 controller.go:195] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"apiserver-eqt674mfxb4j56mrjjkoe7b7ii\": StorageError: invalid object, Code: 4, Key: /registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii, ResourceVersion: 0, AdditionalErrorMsg: Precondition failed: UID in precondition: 1bf55c39-e7a8-4f21-b7c9-07a94fb74e14, UID in object meta: "
E0402 17:18:34.906157       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="system" when="2025-04-02 17:18:34.906144157" prevR="0.08216736ss" incrR="184467440737.09551136ss" currentR="0.08216256ss"
I0402 17:18:35.027380       1 controller.go:615] quota admission added evaluator for: serviceaccounts
I0402 17:18:35.191393       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0402 17:18:35.448456       1 controller.go:615] quota admission added evaluator for: deployments.apps
I0402 17:18:37.559302       1 controller.go:615] quota admission added evaluator for: replicasets.apps
I0402 17:18:37.657815       1 controller.go:615] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0402 17:18:37.858915       1 controller.go:615] quota admission added evaluator for: endpoints
E0402 17:19:08.151548       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-low" when="2025-04-02 17:19:08.151536019" prevR="0.00844586ss" incrR="184467440737.09550717ss" currentR="0.00843687ss"
I0402 17:24:57.373014       1 alloc.go:330] "allocated clusterIPs" service="default/nodejs-app" clusterIPs={"IPv4":"10.99.60.27"}
I0402 17:50:53.679259       1 controller.go:615] quota admission added evaluator for: daemonsets.apps
E0402 18:04:22.928320       1 finisher.go:175] "Unhandled Error" err="FinishRequest: post-timeout activity - time-elapsed: 22.395µs, panicked: false, err: context deadline exceeded, panic-reason: <nil>" logger="UnhandledError"
E0402 18:04:22.931544       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"context canceled\"}: context canceled" logger="UnhandledError"
E0402 18:04:22.932721       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0402 18:04:22.952778       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0402 18:04:22.960508       1 writers.go:123] "Unhandled Error" err="apiserver was unable to write a JSON response: http: Handler timeout" logger="UnhandledError"
E0402 18:04:22.961568       1 status.go:71] "Unhandled Error" err="apiserver received an error that is not an metav1.Status: &errors.errorString{s:\"http: Handler timeout\"}: http: Handler timeout" logger="UnhandledError"
E0402 18:04:22.961752       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0402 18:04:22.979028       1 writers.go:136] "Unhandled Error" err="apiserver was unable to write a fallback JSON response: http: Handler timeout" logger="UnhandledError"
E0402 18:04:22.979196       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="8.255µs" method="GET" path="/apis/coordination.k8s.io/v1/namespaces/ingress-nginx/leases/ingress-nginx-leader" result=null
E0402 18:04:22.980081       1 timeout.go:140] "Post-timeout activity" logger="UnhandledError" timeElapsed="89.060431ms" method="PUT" path="/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube" result=null
E0402 18:04:54.510496       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 18:04:54.510484002" prevR="10.18231077ss" incrR="184467440737.09551594ss" currentR="10.18231055ss"
E0402 18:06:54.528433       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 18:06:54.528408244" prevR="10.21280488ss" incrR="184467440737.09550423ss" currentR="10.21279295ss"
E0402 18:08:56.447091       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 18:08:56.447079236" prevR="10.29564341ss" incrR="184467440737.09550152ss" currentR="10.29562877ss"
E0402 19:39:05.178819       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 19:39:05.178807168" prevR="10.61212518ss" incrR="184467440737.09551488ss" currentR="10.61212390ss"
E0402 19:39:05.879009       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="system" when="2025-04-02 19:39:05.878996265" prevR="2.93341170ss" incrR="184467440737.09550678ss" currentR="2.93340232ss"
E0402 19:39:05.881430       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="system" when="2025-04-02 19:39:05.881420936" prevR="2.93624057ss" incrR="184467440737.09550526ss" currentR="2.93622967ss"
E0402 19:41:05.551742       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 19:41:05.551725080" prevR="10.98194604ss" incrR="184467440737.09551309ss" currentR="10.98194297ss"
E0402 20:00:25.314286       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:00:25.314272385" prevR="11.47619498ss" incrR="184467440737.09551264ss" currentR="11.47619146ss"
E0402 20:05:55.385830       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:05:55.385010158" prevR="11.54386803ss" incrR="184467440737.09551323ss" currentR="11.54386510ss"
E0402 20:08:55.413399       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:08:55.413386832" prevR="11.59667036ss" incrR="184467440737.09550811ss" currentR="11.59666231ss"
E0402 20:08:55.414444       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:08:55.414433627" prevR="11.59667715ss" incrR="184467440737.09551507ss" currentR="11.59667606ss"
E0402 20:10:55.429116       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:10:55.428995924" prevR="11.62291805ss" incrR="184467440737.09550736ss" currentR="11.62290925ss"
E0402 20:11:25.432900       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:11:25.432887417" prevR="11.65200008ss" incrR="184467440737.09550869ss" currentR="11.65199261ss"
E0402 20:14:25.456649       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:14:25.456636098" prevR="11.69125948ss" incrR="184467440737.09550740ss" currentR="11.69125072ss"
E0402 20:15:55.469766       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:15:55.469753894" prevR="11.71877845ss" incrR="184467440737.09549509ss" currentR="11.71875738ss"
E0402 20:17:55.486731       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:17:55.486718089" prevR="11.74502726ss" incrR="184467440737.09551299ss" currentR="11.74502409ss"
E0402 20:17:58.662867       1 conn.go:339] Error on socket receive: read tcp 192.168.49.2:8443->192.168.49.1:40408: use of closed network connection
E0402 20:18:49.490657       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:18:49.490645754" prevR="11.75569462ss" incrR="184467440737.09551282ss" currentR="11.75569128ss"
E0402 20:20:25.506914       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:20:25.506902414" prevR="11.78444177ss" incrR="184467440737.09550388ss" currentR="11.78442949ss"
E0402 20:21:55.531433       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:21:55.531420099" prevR="11.80386850ss" incrR="184467440737.09551375ss" currentR="11.80386609ss"
E0402 20:25:25.563372       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:25:25.563358603" prevR="11.84836772ss" incrR="184467440737.09550015ss" currentR="11.84835171ss"
E0402 20:27:25.584615       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:27:25.584603246" prevR="11.88393687ss" incrR="184467440737.09550357ss" currentR="11.88392428ss"
E0402 20:31:11.232486       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:31:11.232474458" prevR="11.99377413ss" incrR="184467440737.09551082ss" currentR="11.99376879ss"
E0402 20:34:11.271151       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:34:11.271133568" prevR="12.16085636ss" incrR="184467440737.09549631ss" currentR="12.16083651ss"
E0402 20:39:30.510264       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:39:30.510252901" prevR="12.31375288ss" incrR="184467440737.09551196ss" currentR="12.31374868ss"
E0402 20:40:00.515745       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:40:00.515733893" prevR="12.31975362ss" incrR="184467440737.09550238ss" currentR="12.31973984ss"
E0402 20:42:30.539005       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:42:30.538988793" prevR="12.35030229ss" incrR="184467440737.09551195ss" currentR="12.35029808ss"
E0402 20:45:30.565466       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:45:30.565444888" prevR="12.38748907ss" incrR="184467440737.09549555ss" currentR="12.38746846ss"
E0402 20:45:30.566528       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:45:30.566518321" prevR="12.38776884ss" incrR="184467440737.09549215ss" currentR="12.38774483ss"
E0402 20:46:00.568835       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:46:00.568819768" prevR="12.39146204ss" incrR="184467440737.09551303ss" currentR="12.39145891ss"
E0402 20:46:30.573472       1 queueset.go:474] "Overflow" err="queueset::currentR overflow" QS="workload-high" when="2025-04-02 20:46:30.573456227" prevR="12.39804158ss" incrR="184467440737.09550977ss" currentR="12.39803519ss"


==> kube-controller-manager [c8d1ada83c60] <==
I0402 18:04:34.863034       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 18:04:39.747563       1 node_lifecycle_controller.go:1057] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0402 18:07:18.269063       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 18:08:48.296041       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="28.001348ms"
I0402 18:08:48.302463       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="6.256589ms"
I0402 18:08:48.303050       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="61.749µs"
I0402 18:08:48.304560       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="17.248µs"
I0402 18:08:56.447961       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="6.54119ms"
I0402 18:08:56.448043       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="18.205µs"
I0402 18:08:56.485195       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-8c5d666f9" duration="31.79185ms"
I0402 18:08:56.492228       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-8c5d666f9" duration="6.634788ms"
I0402 18:08:56.492272       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-8c5d666f9" duration="18.065µs"
I0402 18:09:26.896925       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-8c5d666f9" duration="27.047µs"
I0402 18:09:27.847417       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-8c5d666f9" duration="536.2µs"
I0402 18:09:27.856294       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-8c5d666f9" duration="23.007µs"
I0402 18:09:27.861203       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-8c5d666f9" duration="29.956µs"
I0402 18:12:24.615242       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 19:39:05.522154       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
E0402 19:39:05.537730       1 node_lifecycle_controller.go:980] "Error updating node" err="Operation cannot be fulfilled on nodes \"minikube\": the object has been modified; please apply your changes to the latest version and try again" logger="node-lifecycle-controller" node="minikube"
I0402 19:41:37.781721       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 19:41:37.791490       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 19:41:42.656200       1 node_lifecycle_controller.go:1038] "Controller detected that all Nodes are not-Ready. Entering master disruption mode" logger="node-lifecycle-controller"
I0402 19:41:48.191065       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 19:41:48.200973       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 19:41:52.657917       1 node_lifecycle_controller.go:1057] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0402 19:48:19.815844       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 19:53:21.371379       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 19:58:29.999150       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:03:35.990248       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:08:45.550310       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:13:50.233266       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:18:51.803722       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:23:57.551199       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:29:41.259663       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:29:41.286132       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:29:46.141970       1 node_lifecycle_controller.go:1038] "Controller detected that all Nodes are not-Ready. Entering master disruption mode" logger="node-lifecycle-controller"
I0402 20:29:51.625198       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:29:51.634362       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:29:56.143482       1 node_lifecycle_controller.go:1057] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0402 20:31:36.098326       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-84df4447dd" duration="35.717912ms"
I0402 20:31:36.107179       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-84df4447dd" duration="8.579702ms"
I0402 20:31:36.107411       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-84df4447dd" duration="24.588µs"
I0402 20:31:36.110832       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-84df4447dd" duration="20.421µs"
I0402 20:31:39.230126       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-84df4447dd" duration="11.383706ms"
I0402 20:31:39.230229       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-84df4447dd" duration="23.265µs"
I0402 20:31:39.269382       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="32.301083ms"
I0402 20:31:39.275512       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="6.094599ms"
I0402 20:31:39.275586       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="19.407µs"
I0402 20:32:09.709518       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="38.364µs"
I0402 20:32:10.604464       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="28.855µs"
I0402 20:32:10.614849       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="33.755µs"
I0402 20:32:10.619191       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/nodejs-app-78d495bc79" duration="19.297µs"
I0402 20:36:00.560533       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:36:00.574514       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:36:05.382096       1 node_lifecycle_controller.go:1038] "Controller detected that all Nodes are not-Ready. Entering master disruption mode" logger="node-lifecycle-controller"
I0402 20:36:10.598880       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:36:10.610583       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:36:15.384528       1 node_lifecycle_controller.go:1057] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0402 20:39:46.942092       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0402 20:44:53.094665       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"


==> kube-controller-manager [d36fd98833e8] <==
I0331 10:27:40.824087       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0331 10:27:40.834635       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0331 10:27:45.748719       1 node_lifecycle_controller.go:1057] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0331 10:32:38.654492       1 garbagecollector.go:789] "failed to discover preferred resources" logger="garbage-collector-controller" error="Get \"https://192.168.49.2:8443/api\": net/http: TLS handshake timeout"
E0331 10:32:38.655766       1 node_lifecycle_controller.go:980] "Error updating node" err="Put \"https://192.168.49.2:8443/api/v1/nodes/minikube/status\": net/http: TLS handshake timeout" logger="node-lifecycle-controller" node="minikube"
E0331 10:32:38.655984       1 resource_quota_controller.go:446] "Unhandled Error" err="failed to discover resources: Get \"https://192.168.49.2:8443/api\": net/http: TLS handshake timeout" logger="UnhandledError"
W0331 10:32:38.656656       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.656687       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Ingress ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.656707       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.PriorityClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.656728       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.PodDisruptionBudget ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:32:38.656764       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.DaemonSet: Get \"https://192.168.49.2:8443/apis/apps/v1/daemonsets?allowWatchBookmarks=true&resourceVersion=32543&timeout=9m21s&timeoutSeconds=561&watch=true\": http2: client connection lost" logger="UnhandledError"
W0331 10:32:38.656789       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ValidatingWebhookConfiguration ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.656809       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ValidatingAdmissionPolicy ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:32:38.656836       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.StatefulSet: Get \"https://192.168.49.2:8443/apis/apps/v1/statefulsets?allowWatchBookmarks=true&resourceVersion=32543&timeout=5m54s&timeoutSeconds=354&watch=true\": http2: client connection lost" logger="UnhandledError"
W0331 10:32:38.656858       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.PersistentVolume ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.656879       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.FlowSchema ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:32:38.656902       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.ClusterRole: Get \"https://192.168.49.2:8443/apis/rbac.authorization.k8s.io/v1/clusterroles?allowWatchBookmarks=true&resourceVersion=32544&timeout=7m34s&timeoutSeconds=454&watch=true\": http2: client connection lost" logger="UnhandledError"
W0331 10:32:38.656923       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ReplicationController ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.656943       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ConfigMap ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.656959       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Namespace ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:32:38.656981       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.CertificateSigningRequest: Get \"https://192.168.49.2:8443/apis/certificates.k8s.io/v1/certificatesigningrequests?allowWatchBookmarks=true&resourceVersion=32545&timeout=7m25s&timeoutSeconds=445&watch=true\": http2: client connection lost" logger="UnhandledError"
W0331 10:32:38.657006       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v2.HorizontalPodAutoscaler ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657024       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ReplicaSet ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657040       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Deployment ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657056       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657192       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.CSIStorageCapacity ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657218       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ControllerRevision ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657233       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.VolumeAttachment ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:32:38.657288       1 reflector.go:166] "Unhandled Error" err="k8s.io/client-go/informers/factory.go:160: Failed to watch *v1.MutatingWebhookConfiguration: Get \"https://192.168.49.2:8443/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations?allowWatchBookmarks=true&resourceVersion=32590&timeout=8m40s&timeoutSeconds=520&watch=true\": http2: client connection lost" logger="UnhandledError"
W0331 10:32:38.657310       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Lease ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657326       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.CronJob ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657345       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ResourceQuota ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657361       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.CSIDriver ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657377       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Job ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657395       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.StorageClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657412       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.RoleBinding ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657431       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.PersistentVolumeClaim ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657450       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ClusterRoleBinding ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657465       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.IngressClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657481       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Pod ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657498       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.CSINode ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657513       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657529       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Role ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657546       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.PriorityLevelConfiguration ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657560       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ValidatingAdmissionPolicyBinding ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657577       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.RuntimeClass ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657592       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.ServiceAccount ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657607       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.NetworkPolicy ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657624       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Endpoints ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657639       1 reflector.go:492] k8s.io/client-go/metadata/metadatainformer/informer.go:138: watch of *v1.PartialObjectMetadata ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657653       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.PodTemplate ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657668       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Secret ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657683       1 reflector.go:492] k8s.io/client-go/metadata/metadatainformer/informer.go:138: watch of *v1.PartialObjectMetadata ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.657696       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.LimitRange ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
E0331 10:56:18.980135       1 node_lifecycle_controller.go:722] "Failed while getting a Node to retry updating node health. Probably Node was deleted" logger="node-lifecycle-controller" node="minikube"
E0331 10:56:18.980157       1 node_lifecycle_controller.go:727] "Update health of Node from Controller error, Skipping - no pods will be evicted" err="Get \"https://192.168.49.2:8443/api/v1/nodes/minikube\": net/http: TLS handshake timeout" logger="node-lifecycle-controller" node=""
I0331 10:56:19.389745       1 range_allocator.go:247] "Successfully synced" logger="node-ipam-controller" key="minikube"
I0331 10:56:19.431850       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="ingress-nginx/ingress-nginx-controller-56d7c84fd4" duration="50.081µs"
I0331 10:56:19.431904       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-668d6bf9bc" duration="30.013µs"
I0331 10:57:07.004799       1 node_lifecycle_controller.go:1234] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""


==> kube-proxy [9df3e5b9f227] <==
I0402 17:18:36.736288       1 server_linux.go:66] "Using iptables proxy"
I0402 17:18:37.039158       1 server.go:698] "Successfully retrieved node IP(s)" IPs=["192.168.49.2"]
E0402 17:18:37.039297       1 server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
I0402 17:18:37.085906       1 server.go:243] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0402 17:18:37.085982       1 server_linux.go:170] "Using iptables Proxier"
I0402 17:18:37.093464       1 proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses" ipFamily="IPv4"
I0402 17:18:37.100910       1 server.go:497] "Version info" version="v1.32.0"
I0402 17:18:37.100959       1 server.go:499] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0402 17:18:37.118521       1 config.go:199] "Starting service config controller"
I0402 17:18:37.121408       1 shared_informer.go:313] Waiting for caches to sync for service config
I0402 17:18:37.123708       1 config.go:105] "Starting endpoint slice config controller"
I0402 17:18:37.123889       1 shared_informer.go:313] Waiting for caches to sync for endpoint slice config
I0402 17:18:37.124298       1 config.go:329] "Starting node config controller"
I0402 17:18:37.124561       1 shared_informer.go:313] Waiting for caches to sync for node config
I0402 17:18:37.223688       1 shared_informer.go:320] Caches are synced for service config
I0402 17:18:37.225392       1 shared_informer.go:320] Caches are synced for endpoint slice config
I0402 17:18:37.225484       1 shared_informer.go:320] Caches are synced for node config


==> kube-proxy [f43a358eee8a] <==
I0331 10:09:45.867936       1 server_linux.go:66] "Using iptables proxy"
I0331 10:09:46.309813       1 server.go:698] "Successfully retrieved node IP(s)" IPs=["192.168.49.2"]
E0331 10:09:46.310030       1 server.go:234] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
I0331 10:09:46.380486       1 server.go:243] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0331 10:09:46.380577       1 server_linux.go:170] "Using iptables Proxier"
I0331 10:09:46.391503       1 proxier.go:255] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses" ipFamily="IPv4"
I0331 10:09:46.403877       1 server.go:497] "Version info" version="v1.32.0"
I0331 10:09:46.405444       1 server.go:499] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0331 10:09:46.413372       1 config.go:329] "Starting node config controller"
I0331 10:09:46.413823       1 shared_informer.go:313] Waiting for caches to sync for node config
I0331 10:09:46.416159       1 config.go:199] "Starting service config controller"
I0331 10:09:46.416522       1 shared_informer.go:313] Waiting for caches to sync for service config
I0331 10:09:46.416750       1 config.go:105] "Starting endpoint slice config controller"
I0331 10:09:46.416812       1 shared_informer.go:313] Waiting for caches to sync for endpoint slice config
I0331 10:09:46.643174       1 shared_informer.go:320] Caches are synced for endpoint slice config
I0331 10:09:46.643367       1 shared_informer.go:320] Caches are synced for service config
I0331 10:09:46.643743       1 shared_informer.go:320] Caches are synced for node config
W0331 10:32:38.563133       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.563188       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0331 10:32:38.563205       1 reflector.go:492] k8s.io/client-go/informers/factory.go:160: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding


==> kube-scheduler [5790212c08ca] <==
I0402 17:18:33.059012       1 serving.go:386] Generated self-signed cert in-memory
I0402 17:18:34.271485       1 server.go:166] "Starting Kubernetes Scheduler" version="v1.32.0"
I0402 17:18:34.271508       1 server.go:168] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0402 17:18:34.283292       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0402 17:18:34.283448       1 requestheader_controller.go:180] Starting RequestHeaderAuthRequestController
I0402 17:18:34.283460       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
I0402 17:18:34.283476       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0402 17:18:34.287826       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0402 17:18:34.287841       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0402 17:18:34.287881       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
I0402 17:18:34.287887       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I0402 17:18:34.385917       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
I0402 17:18:34.388552       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0402 17:18:34.389134       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file


==> kube-scheduler [5c25855d70e2] <==
I0331 10:09:38.502146       1 serving.go:386] Generated self-signed cert in-memory
W0331 10:09:40.541761       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0331 10:09:40.542397       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0331 10:09:40.542512       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0331 10:09:40.544962       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0331 10:09:40.633563       1 server.go:166] "Starting Kubernetes Scheduler" version="v1.32.0"
I0331 10:09:40.633585       1 server.go:168] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0331 10:09:40.635919       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0331 10:09:40.636093       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0331 10:09:40.636137       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0331 10:09:40.637083       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0331 10:09:40.736432       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file


==> kubelet <==
Apr 02 17:18:34 minikube kubelet[1487]: E0402 17:18:34.825317    1487 kubelet.go:3202] "Failed creating a mirror pod" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Apr 02 17:18:34 minikube kubelet[1487]: E0402 17:18:34.825522    1487 kubelet.go:3202] "Failed creating a mirror pod" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Apr 02 17:18:34 minikube kubelet[1487]: I0402 17:18:34.894229    1487 apiserver.go:52] "Watching apiserver"
Apr 02 17:18:34 minikube kubelet[1487]: I0402 17:18:34.989022    1487 desired_state_of_world_populator.go:157] "Finished populating initial desired state of world"
Apr 02 17:18:35 minikube kubelet[1487]: I0402 17:18:35.022636    1487 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/host-path/64624a9f-fb51-4e21-b26c-def5331f91a6-tmp\") pod \"storage-provisioner\" (UID: \"64624a9f-fb51-4e21-b26c-def5331f91a6\") " pod="kube-system/storage-provisioner"
Apr 02 17:18:35 minikube kubelet[1487]: I0402 17:18:35.022768    1487 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/a798e785-0e7c-4c9f-a76b-72622fd635ef-xtables-lock\") pod \"kube-proxy-ddmlm\" (UID: \"a798e785-0e7c-4c9f-a76b-72622fd635ef\") " pod="kube-system/kube-proxy-ddmlm"
Apr 02 17:18:35 minikube kubelet[1487]: I0402 17:18:35.022788    1487 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/a798e785-0e7c-4c9f-a76b-72622fd635ef-lib-modules\") pod \"kube-proxy-ddmlm\" (UID: \"a798e785-0e7c-4c9f-a76b-72622fd635ef\") " pod="kube-system/kube-proxy-ddmlm"
Apr 02 17:18:36 minikube kubelet[1487]: I0402 17:18:36.080009    1487 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="b390cb5ea5563aecd44a018a24b63b77c64dabe8999210ed0afd8d740d8826d2"
Apr 02 17:18:38 minikube kubelet[1487]: I0402 17:18:38.169980    1487 prober_manager.go:312] "Failed to trigger a manual run" probe="Readiness"
Apr 02 17:18:38 minikube kubelet[1487]: I0402 17:18:38.170022    1487 prober_manager.go:312] "Failed to trigger a manual run" probe="Readiness"
Apr 02 17:18:42 minikube kubelet[1487]: I0402 17:18:42.699436    1487 prober_manager.go:312] "Failed to trigger a manual run" probe="Readiness"
Apr 02 17:19:07 minikube kubelet[1487]: I0402 17:19:07.434215    1487 scope.go:117] "RemoveContainer" containerID="02c28ae63c40d4d03d548c8ac529698fee316174e6c7b11f4a82ffcad5082dfd"
Apr 02 17:19:07 minikube kubelet[1487]: I0402 17:19:07.434587    1487 scope.go:117] "RemoveContainer" containerID="36511885d48598776216b0ec381fa5d3a0670088c199c8aee884b14623347b6f"
Apr 02 17:19:07 minikube kubelet[1487]: E0402 17:19:07.434682    1487 pod_workers.go:1301] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"storage-provisioner\" with CrashLoopBackOff: \"back-off 10s restarting failed container=storage-provisioner pod=storage-provisioner_kube-system(64624a9f-fb51-4e21-b26c-def5331f91a6)\"" pod="kube-system/storage-provisioner" podUID="64624a9f-fb51-4e21-b26c-def5331f91a6"
Apr 02 17:19:19 minikube kubelet[1487]: I0402 17:19:19.966754    1487 scope.go:117] "RemoveContainer" containerID="36511885d48598776216b0ec381fa5d3a0670088c199c8aee884b14623347b6f"
Apr 02 17:24:57 minikube kubelet[1487]: I0402 17:24:57.395722    1487 memory_manager.go:355] "RemoveStaleState removing state" podUID="1b3143eb-db61-4d1c-959b-0b019149163f" containerName="patch"
Apr 02 17:24:57 minikube kubelet[1487]: I0402 17:24:57.396120    1487 memory_manager.go:355] "RemoveStaleState removing state" podUID="f73ac5f9-52e0-44eb-8d73-1f9d1b2b2262" containerName="create"
Apr 02 17:24:57 minikube kubelet[1487]: I0402 17:24:57.566558    1487 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-b54rj\" (UniqueName: \"kubernetes.io/projected/f1eb8ca8-ffc7-408b-a8d5-3602ee786826-kube-api-access-b54rj\") pod \"nodejs-app-8c5d666f9-czb22\" (UID: \"f1eb8ca8-ffc7-408b-a8d5-3602ee786826\") " pod="default/nodejs-app-8c5d666f9-czb22"
Apr 02 17:36:02 minikube kubelet[1487]: I0402 17:36:02.508786    1487 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="default/nodejs-app-8c5d666f9-czb22" podStartSLOduration=2.9535605240000002 podStartE2EDuration="11m5.490175348s" podCreationTimestamp="2025-04-02 17:24:57 +0000 UTC" firstStartedPulling="2025-04-02 17:24:58.070767628 +0000 UTC m=+388.701590517" lastFinishedPulling="2025-04-02 17:36:00.607382452 +0000 UTC m=+1051.238205341" observedRunningTime="2025-04-02 17:36:02.479534937 +0000 UTC m=+1053.110357836" watchObservedRunningTime="2025-04-02 17:36:02.490175348 +0000 UTC m=+1053.120998247"
Apr 02 17:50:53 minikube kubelet[1487]: E0402 17:50:53.491205    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 17:52:26 minikube kubelet[1487]: E0402 17:52:26.056245    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 17:55:54 minikube kubelet[1487]: E0402 17:55:54.705596    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 17:55:54 minikube kubelet[1487]: E0402 17:55:54.808926    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 18:04:06 minikube kubelet[1487]: E0402 18:04:06.701261    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 18:04:06 minikube kubelet[1487]: E0402 18:04:06.895990    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 18:04:16 minikube kubelet[1487]: E0402 18:04:16.632469    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 18:04:22 minikube kubelet[1487]: E0402 18:04:22.909231    1487 controller.go:195] "Failed to update lease" err="Put \"https://control-plane.minikube.internal:8443/apis/coordination.k8s.io/v1/namespaces/kube-node-lease/leases/minikube?timeout=10s\": context deadline exceeded"
Apr 02 18:04:22 minikube kubelet[1487]: E0402 18:04:22.918304    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 18:04:24 minikube kubelet[1487]: E0402 18:04:24.507203    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 18:04:24 minikube kubelet[1487]: E0402 18:04:24.555210    1487 controller.go:195] "Failed to update lease" err="Operation cannot be fulfilled on leases.coordination.k8s.io \"minikube\": the object has been modified; please apply your changes to the latest version and try again"
Apr 02 18:04:24 minikube kubelet[1487]: I0402 18:04:24.579410    1487 setters.go:602] "Node became not ready" node="minikube" condition={"type":"Ready","status":"False","lastHeartbeatTime":"2025-04-02T18:04:24Z","lastTransitionTime":"2025-04-02T18:04:24Z","reason":"KubeletNotReady","message":"container runtime is down"}
Apr 02 18:08:48 minikube kubelet[1487]: I0402 18:08:48.332273    1487 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-pcqkb\" (UniqueName: \"kubernetes.io/projected/9c974aea-bbd2-4f47-8565-dd89ed621b21-kube-api-access-pcqkb\") pod \"nodejs-app-78d495bc79-587tt\" (UID: \"9c974aea-bbd2-4f47-8565-dd89ed621b21\") " pod="default/nodejs-app-78d495bc79-587tt"
Apr 02 18:08:56 minikube kubelet[1487]: I0402 18:08:56.470674    1487 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="default/nodejs-app-78d495bc79-587tt" podStartSLOduration=2.033032583 podStartE2EDuration="8.470655657s" podCreationTimestamp="2025-04-02 18:08:48 +0000 UTC" firstStartedPulling="2025-04-02 18:08:49.244773744 +0000 UTC m=+3019.875596632" lastFinishedPulling="2025-04-02 18:08:55.682396817 +0000 UTC m=+3026.313219706" observedRunningTime="2025-04-02 18:08:56.443468025 +0000 UTC m=+3027.074290924" watchObservedRunningTime="2025-04-02 18:08:56.470655657 +0000 UTC m=+3027.101478546"
Apr 02 18:09:26 minikube kubelet[1487]: I0402 18:09:26.936734    1487 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-b54rj\" (UniqueName: \"kubernetes.io/projected/f1eb8ca8-ffc7-408b-a8d5-3602ee786826-kube-api-access-b54rj\") pod \"f1eb8ca8-ffc7-408b-a8d5-3602ee786826\" (UID: \"f1eb8ca8-ffc7-408b-a8d5-3602ee786826\") "
Apr 02 18:09:26 minikube kubelet[1487]: I0402 18:09:26.943826    1487 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f1eb8ca8-ffc7-408b-a8d5-3602ee786826-kube-api-access-b54rj" (OuterVolumeSpecName: "kube-api-access-b54rj") pod "f1eb8ca8-ffc7-408b-a8d5-3602ee786826" (UID: "f1eb8ca8-ffc7-408b-a8d5-3602ee786826"). InnerVolumeSpecName "kube-api-access-b54rj". PluginName "kubernetes.io/projected", VolumeGIDValue ""
Apr 02 18:09:27 minikube kubelet[1487]: I0402 18:09:27.037678    1487 reconciler_common.go:299] "Volume detached for volume \"kube-api-access-b54rj\" (UniqueName: \"kubernetes.io/projected/f1eb8ca8-ffc7-408b-a8d5-3602ee786826-kube-api-access-b54rj\") on node \"minikube\" DevicePath \"\""
Apr 02 18:09:27 minikube kubelet[1487]: I0402 18:09:27.829486    1487 scope.go:117] "RemoveContainer" containerID="68a41946c2cd2fc428e273fe8778a106f944c62e41f50090a97ff80097d39bfb"
Apr 02 18:09:27 minikube kubelet[1487]: I0402 18:09:27.973608    1487 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="f1eb8ca8-ffc7-408b-a8d5-3602ee786826" path="/var/lib/kubelet/pods/f1eb8ca8-ffc7-408b-a8d5-3602ee786826/volumes"
Apr 02 19:39:05 minikube kubelet[1487]: E0402 19:39:05.019139    1487 log.go:32] "ContainerStatus from runtime service failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" containerID="f81139ff4c84439ccec3a7de13f911af2f3cf1e12cfa6537848b24b315cdb6da"
Apr 02 19:39:05 minikube kubelet[1487]: E0402 19:39:05.019166    1487 container_log_manager.go:274] "Failed to get container status" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" worker=1 containerID="f81139ff4c84439ccec3a7de13f911af2f3cf1e12cfa6537848b24b315cdb6da"
Apr 02 19:39:05 minikube kubelet[1487]: E0402 19:39:05.184196    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 19:39:05 minikube kubelet[1487]: E0402 19:39:05.475715    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 19:41:37 minikube kubelet[1487]: E0402 19:41:37.688567    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 19:41:37 minikube kubelet[1487]: I0402 19:41:37.766517    1487 setters.go:602] "Node became not ready" node="minikube" condition={"type":"Ready","status":"False","lastHeartbeatTime":"2025-04-02T19:41:37Z","lastTransitionTime":"2025-04-02T19:41:37Z","reason":"KubeletNotReady","message":"container runtime is down"}
Apr 02 19:49:08 minikube kubelet[1487]: E0402 19:49:08.990868    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 19:49:09 minikube kubelet[1487]: E0402 19:49:09.113944    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 19:49:20 minikube kubelet[1487]: E0402 19:49:20.519804    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 20:11:17 minikube kubelet[1487]: E0402 20:11:17.129488    1487 kubelet.go:2579] "Housekeeping took longer than expected" err="housekeeping took too long" expected="1s" actual="13.163s"
Apr 02 20:29:41 minikube kubelet[1487]: E0402 20:29:41.055337    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 20:29:41 minikube kubelet[1487]: E0402 20:29:41.176175    1487 kubelet.go:2412] "Skipping pod synchronization" err="container runtime is down"
Apr 02 20:29:41 minikube kubelet[1487]: I0402 20:29:41.243288    1487 setters.go:602] "Node became not ready" node="minikube" condition={"type":"Ready","status":"False","lastHeartbeatTime":"2025-04-02T20:29:41Z","lastTransitionTime":"2025-04-02T20:29:41Z","reason":"KubeletNotReady","message":"container runtime is down"}
Apr 02 20:31:36 minikube kubelet[1487]: I0402 20:31:36.096591    1487 memory_manager.go:355] "RemoveStaleState removing state" podUID="f1eb8ca8-ffc7-408b-a8d5-3602ee786826" containerName="nodejs-app"
Apr 02 20:31:36 minikube kubelet[1487]: I0402 20:31:36.288619    1487 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-hznpr\" (UniqueName: \"kubernetes.io/projected/e96de356-74da-43ad-a61c-33908c2dc6b4-kube-api-access-hznpr\") pod \"nodejs-app-84df4447dd-pxv9k\" (UID: \"e96de356-74da-43ad-a61c-33908c2dc6b4\") " pod="default/nodejs-app-84df4447dd-pxv9k"
Apr 02 20:31:39 minikube kubelet[1487]: I0402 20:31:39.247456    1487 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="default/nodejs-app-84df4447dd-pxv9k" podStartSLOduration=1.927215691 podStartE2EDuration="3.247436485s" podCreationTimestamp="2025-04-02 20:31:36 +0000 UTC" firstStartedPulling="2025-04-02 20:31:36.808088088 +0000 UTC m=+11587.438910987" lastFinishedPulling="2025-04-02 20:31:38.128308892 +0000 UTC m=+11588.759131781" observedRunningTime="2025-04-02 20:31:39.220031571 +0000 UTC m=+11589.850854460" watchObservedRunningTime="2025-04-02 20:31:39.247436485 +0000 UTC m=+11589.878259374"
Apr 02 20:32:09 minikube kubelet[1487]: I0402 20:32:09.711738    1487 reconciler_common.go:162] "operationExecutor.UnmountVolume started for volume \"kube-api-access-pcqkb\" (UniqueName: \"kubernetes.io/projected/9c974aea-bbd2-4f47-8565-dd89ed621b21-kube-api-access-pcqkb\") pod \"9c974aea-bbd2-4f47-8565-dd89ed621b21\" (UID: \"9c974aea-bbd2-4f47-8565-dd89ed621b21\") "
Apr 02 20:32:09 minikube kubelet[1487]: I0402 20:32:09.723182    1487 operation_generator.go:780] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/9c974aea-bbd2-4f47-8565-dd89ed621b21-kube-api-access-pcqkb" (OuterVolumeSpecName: "kube-api-access-pcqkb") pod "9c974aea-bbd2-4f47-8565-dd89ed621b21" (UID: "9c974aea-bbd2-4f47-8565-dd89ed621b21"). InnerVolumeSpecName "kube-api-access-pcqkb". PluginName "kubernetes.io/projected", VolumeGIDValue ""
Apr 02 20:32:09 minikube kubelet[1487]: I0402 20:32:09.812831    1487 reconciler_common.go:299] "Volume detached for volume \"kube-api-access-pcqkb\" (UniqueName: \"kubernetes.io/projected/9c974aea-bbd2-4f47-8565-dd89ed621b21-kube-api-access-pcqkb\") on node \"minikube\" DevicePath \"\""
Apr 02 20:32:10 minikube kubelet[1487]: I0402 20:32:10.588412    1487 scope.go:117] "RemoveContainer" containerID="f81139ff4c84439ccec3a7de13f911af2f3cf1e12cfa6537848b24b315cdb6da"
Apr 02 20:32:11 minikube kubelet[1487]: I0402 20:32:11.978532    1487 kubelet_volumes.go:163] "Cleaned up orphaned pod volumes dir" podUID="9c974aea-bbd2-4f47-8565-dd89ed621b21" path="/var/lib/kubelet/pods/9c974aea-bbd2-4f47-8565-dd89ed621b21/volumes"
Apr 02 20:36:00 minikube kubelet[1487]: I0402 20:36:00.544774    1487 setters.go:602] "Node became not ready" node="minikube" condition={"type":"Ready","status":"False","lastHeartbeatTime":"2025-04-02T20:36:00Z","lastTransitionTime":"2025-04-02T20:36:00Z","reason":"KubeletNotReady","message":"container runtime is down"}


==> storage-provisioner [36511885d485] <==
I0402 17:18:36.397995       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0402 17:19:06.420811       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: i/o timeout


==> storage-provisioner [6042ab485271] <==
I0402 17:19:20.155855       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0402 17:19:20.176811       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0402 17:19:20.177688       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0402 17:19:37.580780       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0402 17:19:37.580957       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_35a15324-7879-4396-939b-e3efaf3270de!
I0402 17:19:37.581309       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"7cdbf64d-1d5d-4398-b54e-7f33baadee5d", APIVersion:"v1", ResourceVersion:"32781", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_35a15324-7879-4396-939b-e3efaf3270de became leader
I0402 17:19:37.683946       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_35a15324-7879-4396-939b-e3efaf3270de!
I0402 17:19:37.684054       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 17:19:37.684060       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 17:19:37.689692       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 17:34:37.593904       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 17:34:37.593950       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 17:34:37.595471       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 17:49:37.594145       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 17:49:37.594642       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 17:49:37.595133       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 18:04:37.595224       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 18:04:37.595281       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 18:04:37.595412       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 19:39:04.945384       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 19:39:04.945399       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 19:39:04.945565       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 19:54:25.246028       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 19:54:25.246039       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 19:54:25.246155       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 20:09:25.247041       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 20:09:25.247123       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 20:09:25.247248       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 20:24:25.247512       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 20:24:25.247562       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 20:24:25.247692       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours
I0402 20:39:25.249213       1 controller.go:1472] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": started
I0402 20:39:25.249303       1 storage_provisioner.go:98] Deleting volume &PersistentVolume{ObjectMeta:{pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce    f9a4a44d-0277-4ad5-a92b-6a1716665f27 31795 0 2025-03-24 17:37:50 +0000 UTC <nil> <nil> map[] map[hostPathProvisionerIdentity:6bb8939a-cc21-4849-986b-36ce527fa4b6 pv.kubernetes.io/provisioned-by:k8s.io/minikube-hostpath] [] [kubernetes.io/pv-protection]  [{storage-provisioner Update v1 2025-03-24 17:37:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:hostPathProvisionerIdentity":{},"f:pv.kubernetes.io/provisioned-by":{}}},"f:spec":{"f:accessModes":{},"f:capacity":{".":{},"f:storage":{}},"f:claimRef":{".":{},"f:apiVersion":{},"f:kind":{},"f:name":{},"f:namespace":{},"f:resourceVersion":{},"f:uid":{}},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:persistentVolumeReclaimPolicy":{},"f:storageClassName":{},"f:volumeMode":{}}}} {kube-controller-manager Update v1 2025-03-31 10:11:46 +0000 UTC FieldsV1 {"f:status":{"f:phase":{}}}}]},Spec:PersistentVolumeSpec{Capacity:ResourceList{storage: {{1073741824 0} {<nil>} 1Gi BinarySI},},PersistentVolumeSource:PersistentVolumeSource{GCEPersistentDisk:nil,AWSElasticBlockStore:nil,HostPath:&HostPathVolumeSource{Path:/tmp/hostpath-provisioner/dlopuha/mongo-data-mongo-0,Type:*,},Glusterfs:nil,NFS:nil,RBD:nil,ISCSI:nil,Cinder:nil,CephFS:nil,FC:nil,Flocker:nil,FlexVolume:nil,AzureFile:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Local:nil,StorageOS:nil,CSI:nil,},AccessModes:[ReadWriteOnce],ClaimRef:&ObjectReference{Kind:PersistentVolumeClaim,Namespace:dlopuha,Name:mongo-data-mongo-0,UID:8172d67f-d54e-48e6-be05-d9f6d05999ce,APIVersion:v1,ResourceVersion:2544,FieldPath:,},PersistentVolumeReclaimPolicy:Delete,StorageClassName:standard,MountOptions:[],VolumeMode:*Filesystem,NodeAffinity:nil,},Status:PersistentVolumeStatus{Phase:Released,Message:,Reason:,},}
I0402 20:39:25.249434       1 controller.go:1478] delete "pvc-8172d67f-d54e-48e6-be05-d9f6d05999ce": volume deletion ignored: ignored because identity annotation on PV does not match ours

